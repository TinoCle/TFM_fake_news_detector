{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and feature extraction v4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text, extract stylometric, lexical and complexity features and create a new csv\n",
    "\n",
    "## We are using `spacy`: The NLP *Ruby on Rails* \n",
    "\n",
    "[spacy](http://www.spacy.io/) is a library of natural language processing, robust, fast, easy to install and to use. It can be used with other NLP and Deep Learning Libraries.\n",
    "\n",
    "With its pre-trained models in spanish language, we can operate the typical NLP jobs: Sentences segmentation, tokenization, POS tag, etc...\n",
    "\n",
    "We are going to use the `es_core_news_lg` pre-trained model to make pos tagging:\n",
    "\n",
    "## Also extracting headline features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/corpus_spanish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641</td>\n",
       "      <td>True</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Caras</td>\n",
       "      <td>Sofía Castro y Alejandro Peña Pretelini: una i...</td>\n",
       "      <td>Sofía Castro y Alejandro Peña Pretelini: una i...</td>\n",
       "      <td>https://www.caras.com.mx/sofia-castro-alejandr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Education</td>\n",
       "      <td>Heraldo</td>\n",
       "      <td>Un paso más cerca de hacer los exámenes 'online'</td>\n",
       "      <td>Un paso más cerca de hacer los exámenes 'onlin...</td>\n",
       "      <td>https://www.heraldo.es/noticias/suplementos/he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141</td>\n",
       "      <td>True</td>\n",
       "      <td>Science</td>\n",
       "      <td>HUFFPOST</td>\n",
       "      <td>Esto es lo que los científicos realmente piens...</td>\n",
       "      <td>Esto es lo que los científicos realmente piens...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394</td>\n",
       "      <td>True</td>\n",
       "      <td>Politics</td>\n",
       "      <td>El financiero</td>\n",
       "      <td>Inicia impresión de boletas para elección pres...</td>\n",
       "      <td>Inicia impresión de boletas para elección pres...</td>\n",
       "      <td>http://www.elfinanciero.com.mx/elecciones-2018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139</td>\n",
       "      <td>True</td>\n",
       "      <td>Sport</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>A *NUMBER* día del Mundial</td>\n",
       "      <td>A *NUMBER* día del Mundial\\nFIFA.com sigue la ...</td>\n",
       "      <td>https://es.fifa.com/worldcup/news/a-1-dia-del-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Category          Topic         Source  \\\n",
       "0  641     True  Entertainment          Caras   \n",
       "1    6     True      Education        Heraldo   \n",
       "2  141     True        Science       HUFFPOST   \n",
       "3  394     True       Politics  El financiero   \n",
       "4  139     True          Sport           FIFA   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  Sofía Castro y Alejandro Peña Pretelini: una i...   \n",
       "1   Un paso más cerca de hacer los exámenes 'online'   \n",
       "2  Esto es lo que los científicos realmente piens...   \n",
       "3  Inicia impresión de boletas para elección pres...   \n",
       "4                         A *NUMBER* día del Mundial   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Sofía Castro y Alejandro Peña Pretelini: una i...   \n",
       "1  Un paso más cerca de hacer los exámenes 'onlin...   \n",
       "2  Esto es lo que los científicos realmente piens...   \n",
       "3  Inicia impresión de boletas para elección pres...   \n",
       "4  A *NUMBER* día del Mundial\\nFIFA.com sigue la ...   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.caras.com.mx/sofia-castro-alejandr...  \n",
       "1  https://www.heraldo.es/noticias/suplementos/he...  \n",
       "2  https://www.huffingtonpost.com/entry/scientist...  \n",
       "3  http://www.elfinanciero.com.mx/elecciones-2018...  \n",
       "4  https://es.fifa.com/worldcup/news/a-1-dia-del-...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(971, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id           int64\n",
       "Category    object\n",
       "Topic       object\n",
       "Source      object\n",
       "Headline    object\n",
       "Text        object\n",
       "Link        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 971 entries, 0 to 970\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Id        971 non-null    int64 \n",
      " 1   Category  971 non-null    object\n",
      " 2   Topic     971 non-null    object\n",
      " 3   Source    971 non-null    object\n",
      " 4   Headline  971 non-null    object\n",
      " 5   Text      971 non-null    object\n",
      " 6   Link      971 non-null    object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 53.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>151</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Science</td>\n",
       "      <td>Publimetro</td>\n",
       "      <td>Tendremos otra Era de Hielo en *NUMBER* según ...</td>\n",
       "      <td>Tendremos otra Era de Hielo en *NUMBER* según ...</td>\n",
       "      <td>https://www.publimetro.cl/cl/mundo/2016/10/05/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>534</td>\n",
       "      <td>True</td>\n",
       "      <td>Politics</td>\n",
       "      <td>El Universal</td>\n",
       "      <td>AMLO dispone de hasta *NUMBER* millones de pes...</td>\n",
       "      <td>AMLO dispone de hasta *NUMBER* millones de pes...</td>\n",
       "      <td>http://www.eluniversal.com.mx/elecciones-2018/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>98</td>\n",
       "      <td>Fake</td>\n",
       "      <td>Society</td>\n",
       "      <td>El Dizque</td>\n",
       "      <td>Un grupo de expertos descubre los pasos a segu...</td>\n",
       "      <td>Un grupo de expertos descubre los pasos a segu...</td>\n",
       "      <td>https://www.eldizque.com/un-grupo-de-expertos-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>166</td>\n",
       "      <td>True</td>\n",
       "      <td>Politics</td>\n",
       "      <td>El país</td>\n",
       "      <td>Túnez ya cuenta con la primera alcaldesa elect...</td>\n",
       "      <td>Túnez ya cuenta con la primera alcaldesa elect...</td>\n",
       "      <td>https://elpais.com/internacional/2018/07/03/ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>504</td>\n",
       "      <td>True</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Excelsior</td>\n",
       "      <td>La CDMX enfrenta contingencia por falta de agua</td>\n",
       "      <td>La CDMX enfrenta contingencia por falta de agu...</td>\n",
       "      <td>https://www.excelsior.com.mx/comunidad/la-cdmx...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id Category     Topic        Source  \\\n",
       "272  151     Fake   Science    Publimetro   \n",
       "157  534     True  Politics  El Universal   \n",
       "228   98     Fake   Society     El Dizque   \n",
       "448  166     True  Politics       El país   \n",
       "280  504     True  Politics     Excelsior   \n",
       "\n",
       "                                              Headline  \\\n",
       "272  Tendremos otra Era de Hielo en *NUMBER* según ...   \n",
       "157  AMLO dispone de hasta *NUMBER* millones de pes...   \n",
       "228  Un grupo de expertos descubre los pasos a segu...   \n",
       "448  Túnez ya cuenta con la primera alcaldesa elect...   \n",
       "280    La CDMX enfrenta contingencia por falta de agua   \n",
       "\n",
       "                                                  Text  \\\n",
       "272  Tendremos otra Era de Hielo en *NUMBER* según ...   \n",
       "157  AMLO dispone de hasta *NUMBER* millones de pes...   \n",
       "228  Un grupo de expertos descubre los pasos a segu...   \n",
       "448  Túnez ya cuenta con la primera alcaldesa elect...   \n",
       "280  La CDMX enfrenta contingencia por falta de agu...   \n",
       "\n",
       "                                                  Link  \n",
       "272  https://www.publimetro.cl/cl/mundo/2016/10/05/...  \n",
       "157  http://www.eluniversal.com.mx/elecciones-2018/...  \n",
       "228  https://www.eldizque.com/un-grupo-de-expertos-...  \n",
       "448  https://elpais.com/internacional/2018/07/03/ac...  \n",
       "280  https://www.excelsior.com.mx/comunidad/la-cdmx...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La CDMX enfrenta contingencia por falta de agua\\nLa presencia de un canal de alta presión y las altas temperaturas afectaron la distribución a *NUMBER* mil habitantes en *NUMBER* delegaciones\\nVecinos de la delegación Tláhuac cerraron un tramo de la avenida del mismo nombre y Calle *NUMBER* para manifestar su inconformidad por la falta de agua potable que padecen en ésa y otras zonas de la Ciudad de México.\\nEn las delegaciones Cuauhtémoc, Benito Juárez, Iztapalapa, Iztacalco, Venustiano Carranza, Azcapotzalco y Tlalpan se enfrenta una contingencia por escasez y por baja presión de agua.\\nDe acuerdo con las autoridades, aproximadamente, *NUMBER* mil habitantes de las siete demarcaciones padecen la escasez debido a la presencia atípica de un canal de alta presión que originó que se dejaran de recibir *NUMBER* mil litros de agua por segundo del Sistema Cutzamala, además de que, por las altas temperaturas, en algunas zonas, se incrementó hasta *NUMBER* por ciento el consumo del líquido, situación que mermó la distribución en otras partes.\\nJosé Ramón Aguirre, director general del Sistema de Aguas de la Ciudad de México, detalló que \"diez por ciento de la ciudad son *NUMBER* mil habitantes, por eso hablamos de que estamos en una emergencia y contingencia. Estamos con presiones bajas en buena parte de la ciudad, en delegaciones como Cuauhtémoc y Benito Juárez, hemos tenido quejas de vecinos por baja presión\".\\nAgregó que hay zonas donde no se ha podido cumplir con el tandeo completo, como Iztapalapa; además de que se atienden quejas con pipas de agua en Iztacalco, Venustiano Carranza, mientras que en Azcapotzalco está una situación fuera de lo normal provocada por una cuestión climatológica severa.\\nPor lo anterior, se puso en marcha un operativo especial para la entrega de agua a través de pipas en las colonias en las cuales, desde hace días, dejaron de recibirla.\\nGuillermo Orozco, secretario de Gobierno, detalló que el número de pipas que se han conjuntado en coordinación con Sacmex serán, aproximadamente, *NUMBER* pipas diarias que estarán disponibles para atender la demanda de la ciudadanía. Las pipas tienen la capacidad de hacer hasta tres viajes diarios, lo que permitiría distribuir unos *NUMBER* millones de litros al día.\\nPara verificar que no se lucre con la distribución del agua, la Contraloría General instalará un módulo de atención y *NUMBER* servidores públicos de la Secretaría de la Contraloría, apoyados con *NUMBER* unidades vehiculares, se mantendrán atentos.\\nEduardo Rovelo, contralor General de la ciudad, indicó que la intención es dar certeza de que la distribución sea correcta y que los servidores públicos actúen de manera profesional, ética y disciplinada.\\nEn tanto, *NUMBER* trabajadores de la Secretaría de Desarrollo Social acudirán a las zonas afectadas para coordinar la entrega de las pipas.\\nSe prevé que esta situación se regularice a finales de la próxima semana, en tanto, las autoridades hicieron un llamado a la población a que, si cuenta con el servicio, racionen el uso de agua, ya que, advirtieron, podrían padecer su carencia.'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = df['Text'].iloc[280]\n",
    "\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'la cdmx enfrenta contingencia por falta de agua la presencia de un canal de alta presión y las altas temperaturas afectaron la distribución a número mil habitantes en número delegaciones vecinos de la delegación tláhuac cerraron un tramo de la avenida del mismo nombre y calle número para manifestar su inconformidad por la falta de agua potable que padecen en ésa y otras zonas de la ciudad de méxico. en las delegaciones cuauhtémoc, benito juárez, iztapalapa, iztacalco, venustiano carranza, azcapotzalco y tlalpan se enfrenta una contingencia por escasez y por baja presión de agua. de acuerdo con las autoridades, aproximadamente, número mil habitantes de las siete demarcaciones padecen la escasez debido a la presencia atípica de un canal de alta presión que originó que se dejaran de recibir número mil litros de agua por segundo del sistema cutzamala, además de que, por las altas temperaturas, en algunas zonas, se incrementó hasta número por ciento el consumo del líquido, situación que mermó la distribución en otras partes. josé ramón aguirre, director general del sistema de aguas de la ciudad de méxico, detalló que \"diez por ciento de la ciudad son número mil habitantes, por eso hablamos de que estamos en una emergencia y contingencia. estamos con presiones bajas en buena parte de la ciudad, en delegaciones como cuauhtémoc y benito juárez, hemos tenido quejas de vecinos por baja presión\". agregó que hay zonas donde no se ha podido cumplir con el tandeo completo, como iztapalapa; además de que se atienden quejas con pipas de agua en iztacalco, venustiano carranza, mientras que en azcapotzalco está una situación fuera de lo normal provocada por una cuestión climatológica severa. por lo anterior, se puso en marcha un operativo especial para la entrega de agua a través de pipas en las colonias en las cuales, desde hace días, dejaron de recibirla. guillermo orozco, secretario de gobierno, detalló que el número de pipas que se han conjuntado en coordinación con sacmex serán, aproximadamente, número pipas diarias que estarán disponibles para atender la demanda de la ciudadanía. las pipas tienen la capacidad de hacer hasta tres viajes diarios, lo que permitiría distribuir unos número millones de litros al día. para verificar que no se lucre con la distribución del agua, la contraloría general instalará un módulo de atención y número servidores públicos de la secretaría de la contraloría, apoyados con número unidades vehiculares, se mantendrán atentos. eduardo rovelo, contralor general de la ciudad, indicó que la intención es dar certeza de que la distribución sea correcta y que los servidores públicos actúen de manera profesional, ética y disciplinada. en tanto, número trabajadores de la secretaría de desarrollo social acudirán a las zonas afectadas para coordinar la entrega de las pipas. se prevé que esta situación se regularice a finales de la próxima semana, en tanto, las autoridades hicieron un llamado a la población a que, si cuenta con el servicio, racionen el uso de agua, ya que, advirtieron, podrían padecer su carencia.'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = re.sub(r\"http\\S+\", \"\", text)\n",
    "text = re.sub(r\"@\\S+\", \"\", text)\n",
    "text = re.sub(\"\\n\", \" \", text)\n",
    "text = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", text)\n",
    "text = text.replace(r\"*NUMBER*\", \"número\")\n",
    "text = text.replace(r\"*PHONE*\", \"número\")\n",
    "text = text.replace(r\"*EMAIL*\", \"email\")\n",
    "text = text.replace(r\"*URL*\", \"url\")\n",
    "text = text.lower()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syltippy import syllabize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllables= syllabize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['la', ' u', 'nam', ' lim', 'pia', ' au', 'las ', 'de', ' a', 'lum', 'nos', ' re', 'za', 'ga', 'dos', ' a ', 'par', 'tir ', 'de ', 'nú', 'me', 'ro,', ' las ', 'nue', 'vas', ' re', 'glas ', 'de', ' in', 'gre', 'so ', 'y ', 'per', 'ma', 'nen', 'cia ', 'co', 'men', 'za', 'ron', ' a', ' a', 'li', 'ge', 'rar', ' la ', 'car', 'ga', ' ad', 'mi', 'nis', 'tra', 'ti', 'va', ' en', ' la', ' u', 'nam;', ' ter', 'mi', 'nan ', 'con ', 'nú', 'me', 'ro% ', 'de ', 'fó', 'si', 'les', ' en ', 'ca', 'si ', 'nú', 'me', 'ro', ' a', 'ños ', 'ciu', 'dad ', 'de ', 'mé', 'xi', 'co, ', 'nú', 'me', 'ro ', 'de ', 'sep', 'tiem', 'bre.-', ' a', 'go', 'bia', 'da ', 'du', 'ran', 'te ', 'dé', 'ca', 'das ', 'por', ' la', ' e', 'xis', 'ten', 'cia ', 'de ', 'cer', 'ca ', 'de ', 'me', 'dio ', 'mi', 'llón ', 'de', ' a', 'lum', 'nos ', 'que ', 'se', ' e', 'ter', 'ni', 'za', 'ban', ' en ', 'sus', ' au', 'las,', ' de ', 'los ', 'cua', 'les ', 'po', 'co ', 'más ', 'de ', 'nú', 'me', 'ro ', 'mil ', 'man', 'te', 'ní', 'an ', 'vi', 'va ', 'su', ' ac', 'ti', 'vi', 'dad', ' ad', 'mi', 'nis', 'tra', 'ti', 'va', ' has', 'ta', ' ha', 'ce ', 'nú', 'me', 'ro', ' a', 'ños,', ' la', ' u', 'nam ', 'ven', 'ció', ' el', ' au', 'men', 'to ', 'de ', 'sus', ' a', 'lum', 'nos', ' re', 'za', 'ga', 'dos', ' en ', 'nú', 'me', 'ro%,', ' pe', 'ro', ' a', 'de', 'más', ' e', 'le', 'vó', ' en ', 'nú', 'me', 'ro%', ' el', ' e', 'gre', 'so', ' o', 'por', 'tu', 'no ', 'de ', 'su ', 'ba', 'chi', 'lle', 'ra', 'to ', 'pa', 'ra', ' u', 'sar', ' el ', 'pa', 'se ', 're', 'gla', 'men', 'ta', 'do', ' a ', 'li', 'cen', 'cia', 'tu', 'ra.', ' el', ' a', 'van', 'ce', ' en', ' es', 'tas ', 'ci', 'fras,', ' que ', 'sig', 'ni', 'fi', 'ca', 'ron ', 'pa', 'ra ', 'la', ' u', 'nam', ' un', ' las', 'tre ', 'y', ' u', 'na ', 'cons', 'tan', 'te ', 'pre', 'sión ', 'de ', 'gru', 'pos', ' ac', 'ti', 'vis', 'tas,', ' for', 'ma ', 'par', 'te ', 'del ', 'per', 'fil ', 'que ', 'tie', 'ne', ' a', 'ho', 'ra ', 'la ', 'má', 'xi', 'ma ', 'ca', 'sa ', 'de', ' es', 'tu', 'dios', ' y ', 'que ', 'jo', 'sé ', 'na', 'rro ', 'ro', 'bles', ' en', 'tre', 'ga', 'rá', ' a ', 'su ', 'su', 'ce', 'sor', ' el ', 'pró', 'xi', 'mo ', 'nú', 'me', 'ro ', 'de ', 'no', 'viem', 'bre. ', 'de', ' a', 'cuer', 'do ', 'con', ' las ', 'ci', 'fras ', 'his', 'tó', 'ri', 'cas ', 'de ', 'la', ' u', 'nam,', ' que ', 'pa', 'ra', ' el ', 'ca', 'so ', 'de ', 'los', ' a', 'lum', 'nos', ' e', 'gre', 'sa', 'dos', ' es ', 'has', 'ta', ' el ', 'ci', 'clo', ' es', 'co', 'lar ', 'nú', 'me', 'ro-', 'nú', 'me', 'ro ', 'y ', 'pa', 'ra', ' el ', 'ca', 'so ', 'de ', 'los', ' a', 'lum', 'nos ', 'de ', 'nue', 'vo', ' in', 'gre', 'so ', 'y ', 'rein', 'gre', 'so', ' es ', 'has', 'ta', ' el ', 'ci', 'clo', ' es', 'co', 'lar ', 'nú', 'me', 'ro-', 'nú', 'me', 'ro,', ' la ', 're', 'for', 'ma ', 'de ', 'nú', 'me', 'ro ', 'que ', 'pu', 'so ', 'fin', ' al', ' lla', 'ma', 'do ', 'pa', 'se', ' au', 'to', 'má', 'ti', 'co ', 'del ', 'ba', 'chi', 'lle', 'ra', 'to', ' a ', 'la ', 'li', 'cen', 'cia', 'tu', 'ra ', 'y ', 'pu', 'so ', 'lí', 'mi', 'tes', ' a ', 'la ', 'per', 'ma', 'nen', 'cia ', 'de ', 'los', ' a', 'lum', 'nos', ' en', ' la', ' ins', 'ti', 'tu', 'ción,', ' co', 'men', 'zó', ' a ', 'dar', ' re', 'sul', 'ta', 'dos', ' a ', 'par', 'tir ', 'de ', 'nú', 'me', 'ro, ', 'pa', 'ra ', 'que', ' ac', 'tual', 'men', 'te ', 'la ', 'car', 'ga', ' ad', 'mi', 'nis', 'tra', 'ti', 'va ', 'de ', 'los', ' lla', 'ma', 'dos ', 'fó', 'si', 'les ', 'se ', 're', 'du', 'je', 'ra ', 'con', 'si', 'de', 'ra', 'ble', 'men', 'te.', ' las ', 'nue', 'vas', ' re', 'glas ', 'de', ' in', 'gre', 'so ', 'y ', 'per', 'ma', 'nen', 'cia', ' en', ' el ', 'ba', 'chi', 'lle', 'ra', 'to ', 'y ', 'la ', 'li', 'cen', 'cia', 'tu', 'ra ', 'de ', 'la', ' u', 'nam,', ' a', 'pro', 'ba', 'das', ' en ', 'nú', 'me', 'ro ', 'por', ' el ', 'con', 'se', 'jo', ' u', 'ni', 'ver', 'si', 'ta', 'rio,', ' a', ' ins', 'tan', 'cias ', 'del', ' en', 'ton', 'ces', ' rec', 'tor ', 'fran', 'cis', 'co ', 'bar', 'nés ', 'de ', 'cas', 'tro,', ' es', 'ta', 'ble', 'cen ', 'que ', 'los ', 'ba', 'chi', 'lle', 'res ', 'só', 'lo ', 'pue', 'den', ' es', 'tar', ' ins', 'cri', 'tos', ' en', ' la', ' ins', 'ti', 'tu', 'ción ', 'du', 'ran', 'te ', 'cua', 'tro', ' a', 'ños;', ' es ', 'de', 'cir,', ' un', ' a', 'ño ', 'más ', 'de ', 'los ', 'tres', ' en', ' los ', 'que ', 'de', 'ben ', 'con', 'cluir ', 'sus', ' es', 'tu', 'dios.', ' re', 'ba', 'sa', 'dos', ' e', 'sos ', 'cua', 'tro', ' a', 'ños ', 'só', 'lo ', 'tie', 'nen ', 'de', 're', 'cho', ' a ', 'pre', 'sen', 'tar', ' e', 'xá', 'me', 'nes', ' ex', 'tra', 'or', 'di', 'na', 'rios ', 'pa', 'ra', ' a', 'cre', 'di', 'tar', ' las ', 'ma', 'te', 'rias,', ' pe', 'ro', ' ú', 'ni', 'ca', 'men', 'te ', 'por ', 'dos', ' a', 'ños ', 'más;', ' es ', 'de', 'cir,', ' los', ' a', 'do', 'les', 'cen', 'tes ', 'que', ' en', 'tra', 'ron', ' al ', 'co', 'le', 'gio ', 'de ', 'cien', 'cias', ' y', ' hu', 'ma', 'ni', 'da', 'des ', '(cch) o', ' a ', 'la', ' es', 'cue', 'la ', 'na', 'cio', 'nal ', 'pre', 'pa', 'ra', 'to', 'ria ', '(enp', ') en ', 'nú', 'me', 'ro ', 'cau', 'sa', 'ron ', 'ba', 'ja ', 'de', 'fi', 'ni', 'ti', 'va ', 'seis', ' a', 'ños ', 'des', 'pués,', ' en ', 'nú', 'me', 'ro, ', 'por', ' lo ', 'que', ' en', ' el ', 'ba', 'chi', 'lle', 'ra', 'to', ' u', 'na', 'mi', 'ta ', 'ya ', 'no', ' e', 'xis', 'te ', 'ni', ' u', 'no ', 'de ', 'los ', 'nue', 've ', 'mil ', 'nú', 'me', 'ro', ' a', 'lum', 'nos ', 'de ', 'la ', 'ge', 'ne', 'ra', 'ción ', 'nú', 'me', 'ro ', 'que ', 'no ', 'ter', 'mi', 'na', 'ron', ' en ', 'tres', ' a', 'ños', ' es', 'te ', 'gra', 'do', ' es', 'co', 'lar.', ' pa', 'ra', ' el ', 'ca', 'so ', 'de ', 'la ', 'li', 'cen', 'cia', 'tu', 'ra,', ' el', ' re', 'gla', 'men', 'to ', 'ge', 'ne', 'ral ', 'de', ' ins', 'crip', 'cio', 'nes ', 'de ', 'la', ' u', 'nam', ' or', 'de', 'na ', 'que ', 'los', ' a', 'lum', 'nos ', 'que ', 'no', ' ha', 'yan ', 'po', 'di', 'do ', 'con', 'cluir ', 'su ', 'ca', 'rre', 'ra', ' en', ' el ', 'tiem', 'po ', 're', 'gla', 'men', 'ta', 'rio ', '(la', ' in', 'men', 'sa ', 'ma', 'yo', 'rí', 'a ', 'de ', 'las ', 'ca', 'rre', 'ras', ' es ', 'de ', 'cua', 'tro', ' a', 'ños)', ' ten', 'drán ', 'de', 're', 'cho', ' a ', 'fi', 'na', 'li', 'zar', ' la ', 'ca', 'rre', 'ra', ' en ', 'dos', ' a', 'ños ', 'más;', ' es ', 'de', 'cir,', ' pa', 'ra', ' u', 'na ', 'ca', 'rre', 'ra ', 'de ', 'cua', 'tro', ' a', 'ños,', ' el ', 'má', 'xi', 'mo', ' es ', 'de ', 'seis', ' a', 'ños.', ' pe', 'ro ', 'si', ' al ', 'tér', 'mi', 'no ', 'de', ' e', 'se ', 'tiem', 'po ', 'no ', 'pu', 'die', 'ron ', 'con', 'cluir,', ' só', 'lo ', 'pue', 'den ', 'man', 'te', 'ner', 'se', ' en', ' la', ' u', 'nam', ' un ', 'nú', 'me', 'ro% ', 'de ', 'tiem', 'po ', 'más;', ' ya ', 'no ', 'pue', 'den ', 'ser', ' a', 'lum', 'nos,', ' si', 'no ', 'só', 'lo ', 'pre', 'sen', 'tar', ' ex', 'tra', 'or', 'di', 'na', 'rios;', ' es ', 'de', 'cir,', ' pa', 'ra', ' u', 'na ', 'ca', 'rre', 'ra ', 'de ', 'cua', 'tro', ' a', 'ños,', ' el ', 'má', 'xi', 'mo ', 'pa', 'ra ', 'per', 'ma', 'ne', 'cer', ' en', ' la', ' u', 'nam', ' es ', 'de', ' o', 'cho', ' a', 'ños;', ' nin', 'gu', 'no ', 'de ', 'los ', 'tres ', 'mil ', 'nú', 'me', 'ro ', 'jó', 've', 'nes ', 'de ', 'la ', 'ge', 'ne', 'ra', 'ción ', 'nú', 'me', 'ro ', 'que ', 'no ', 'con', 'clu', 'yó ', 'su ', 'ca', 'rre', 'ra', ' es', 'tá', ' a', 'ho', 'ra', ' en', ' la', ' u', 'nam,', ' pues', ' los', ' úl', 'ti', 'mos ', 'tu', 'vie', 'ron ', 'de', 're', 'cho', ' a', ' e', 'xá', 'me', 'nes', ' ex', 'tra', 'or', 'di', 'na', 'rios ', 'has', 'ta ', 'nú', 'me', 'ro,', ' y ', 'ni', ' un ', 'se', 'mes', 'tre ', 'más.', ' el ', 'pa', 'se ', 're', 'gla', 'men', 'ta', 'do ', 'de', ' a', 'cuer', 'do ', 'con', ' el ', 'diag', 'nós', 'ti', 'co', ' o', 'fi', 'cial ', 'que ', 'lle', 'vó', ' al ', 'con', 'se', 'jo', ' u', 'ni', 'ver', 'si', 'ta', 'rio', ' a ', 're', 'for', 'mar', ' las', ' re', 'glas ', 'de', ' in', 'gre', 'so ', 'y ', 'per', 'ma', 'nen', 'cia ', 'de ', 'sus', ' es', 'tu', 'dian', 'tes', ' en', ' las', ' au', 'las,', ' el', ' en', 'ton', 'ces ', 'pa', 'se', ' au', 'to', 'má', 'ti', 'co ', 'del ', 'ba', 'chi', 'lle', 'ra', 'to', ' a ', 'la ', 'li', 'cen', 'cia', 'tu', 'ra ', 'fue', ' un ', 'fac', 'tor ', 'fun', 'da', 'men', 'tal ', 'pa', 'ra ', 'que ', 'los ', 'jó', 've', 'nes ', 'no ', 'con', 'clu', 'ye', 'ran ', 'sus', ' es', 'tu', 'dios', ' en', ' el ', 'tiem', 'po', ' es', 'ta', 'ble', 'ci', 'do.', ' las ', 'ci', 'fras', ' ac', 'tua', 'les ', 'com', 'prue', 'ban ', 'que ', 'los', ' lí', 'mi', 'tes', ' es', 'ta', 'ble', 'ci', 'dos ', 'pa', 'ra ', 'te', 'ner ', 'de', 're', 'cho', ' a', ' ins', 'crip', 'ción', ' y ', 'pa', 'se ', 're', 'gla', 'men', 'ta', 'do ', 'fun', 'cio', 'nó.', ' en', ' el ', 'ci', 'clo', ' es', 'co', 'lar ', 'nú', 'me', 'ro, ', 'que ', 'fue ', 'la ', 'ter', 'ce', 'ra ', 'ge', 'ne', 'ra', 'ción', ' a ', 'la ', 'que', ' a', 'pli', 'ca', 'ron', ' las ', 'nue', 'vas', ' re', 'glas,', ' nú', 'me', 'ro ', 'mil ', 'nú', 'me', 'ro ', 'jó', 've', 'nes ', 'hi', 'cie', 'ron ', 'su ', 'so', 'li', 'ci', 'tud ', 'pa', 'ra', ' in', 'gre', 'sar', ' a', ' al', 'gu', 'na ', 'de ', 'las ', 'ca', 'rre', 'ras ', 'de ', 'la', ' u', 'ni', 'ver', 'si', 'dad ', 'na', 'cio', 'nal;', ' de', ' e', 'llos,', ' nú', 'me', 'ro ', 'mil ', 'nú', 'me', 'ro ', 'con', 'clu', 'yó ', 'su', ' ins', 'crip', 'ción ', 'pa', 'ra ', 'con', 'ti', 'nuar', ' los', ' es', 'tu', 'dios.', ' a', 'ho', 'ra,', ' la', ' u', 'nam', ' re', 'por', 'tó ', 'que ', 'pa', 'ra', ' el ', 'ci', 'clo', ' es', 'co', 'lar ', 'nú', 'me', 'ro-', 'nú', 'me', 'ro ', 'fue', 'ron ', 'nú', 'me', 'ro ', 'mil ', 'nú', 'me', 'ro ', 'los ', 'jó', 've', 'nes ', 'que ', 'pre', 'sen', 'ta', 'ron ', 'so', 'li', 'ci', 'tud ', 'pa', 'ra', ' el', ' u', 'so ', 'del ', 'pa', 'se ', 're', 'gla', 'men', 'ta', 'do;', ' es ', 'de', 'cir,', ' tres ', 'mil ', 'nú', 'me', 'ro', ' a', 'lum', 'nos ', 'más,', ' que', ' im', 'pli', 'can', ' un', ' au', 'men', 'to ', 'de ', 'nú', 'me', 'ro ', 'por ', 'cien', 'to. ', 'pe', 'ro ', 'se', ' ob', 'ser', 'va ', 'que', ' en', ' e', 'se ', 'ci', 'clo', ' es', 'co', 'lar,', ' el ', 'más', ' re', 'cien', 'te ', 'que', ' in', 'clu', 'yen', ' las', ' es', 'ta', 'dís', 'ti', 'cas ', 'de ', 'la', ' u', 'nam,', ' nú', 'me', 'ro ', 'mil ', 'nú', 'me', 'ro ', 'jó', 've', 'nes ', 'con', 'clu', 'ye', 'ron ', 'sus ', 'trá', 'mi', 'tes ', 'de', ' ins', 'crip', 'ción,', ' lo ', 'que', ' im', 'pli', 'ca ', 'que ', 'cua', 'tro ', 'mil ', 'nú', 'me', 'ro', ' a', 'lum', 'nos ', 'más ', 'que', ' en ', 'nú', 'me', 'ro ', 'de', 'ci', 'die', 'ron ', 'con', 'ti', 'nuar ', 'con ', 'sus', ' es', 'tu', 'dios ', 'pro', 'fe', 'sio', 'na', 'les,', ' lo ', 'que', ' im', 'pli', 'ca', ' u', 'na ', 'me', 'jo', 'ra', ' en', ' el', ' u', 'so ', 'del ', 'pa', 'se ', 're', 'gla', 'men', 'ta', 'do ', 'de ', 'nú', 'me', 'ro%', ' en', ' el', ' e', 'gre', 'so', ' o', 'por', 'tu', 'no ', 'de ', 'los', ' a', 'lum', 'nos.', ' a', 'lum', 'nos', ' e', 'ter', 'nos ', 'pe', 'ro', ' el', ' lo', 'gro ', 'más ', 'tras', 'cen', 'den', 'te ', 'pa', 'ra ', 'la', ' u', 'ni', 'ver', 'si', 'dad ', 'na', 'cio', 'nal', ' lo ', 're', 'gis', 'tran ', 'sus', ' es', 'ta', 'dís', 'ti', 'cas', ' en ', 'tor', 'no', ' a ', 'la', ' e', 'xis', 'ten', 'cia ', 'de ', 'los', ' a', 'lum', 'nos', ' re', 'za', 'ga', 'dos ', 'por', ' a', 'ños,', ' que', ' en', ' el ', 'mun', 'do', ' in', 'ter', 'no ', 'de ', 'la', ' ins', 'ti', 'tu', 'ción ', 'se ', 'les ', 'co', 'no', 'ció ', 'co', 'mo ', 'fó', 'si', 'les.', ' la', ' u', 'ni', 'ver', 'si', 'dad ', 'te', 'ní', 'a', ' un', ' a', 'cu', 'mu', 'la', 'do ', 'de', ' al', 're', 'de', 'dor ', 'de ', 'me', 'dio ', 'mi', 'llón ', 'de ', 'per', 'so', 'nas ', 'que ', 'se', ' ha', 'bí', 'an', ' ins', 'cri', 'to', ' en ', 'sus', ' au', 'las', ' y ', 'que ', 'no ', 'con', 'cluí', 'an', ' los', ' es', 'tu', 'dios,', ' pe', 'ro ', 'que ', 'des', 'de ', 'nú', 'me', 'ro ', 'te', 'ní', 'an', ' el ', 'de', 're', 'cho', ' a ', 'man', 'te', 'ner ', 'vi', 'vos ', 'sus ', 'de', 're', 'chos ', 'co', 'mo', ' a', 'lum', 'nos ', 'de ', 'la', ' ins', 'ti', 'tu', 'ción,', ' lo ', 'que ', 'dio ', 'pa', 'so', ' a ', 'la', ' e', 'xis', 'ten', 'cia ', 'de', ' a', 'lum', 'nos ', 'que ', 're', 'pro', 'ba', 'ban ', 'has', 'ta', ' en ', 'nú', 'me', 'ro', ' o', 'ca', 'sio', 'nes', ' y', ' aun', ' a', 'sí ', 'te', 'ní', 'an ', 'de', 're', 'cho ', 'co', 'mo', ' un', ' a', 'lum', 'no ', 're', 'gu', 'lar;', ' hu', 'bo', ' un ', 'ca', 'so', ' en', ' la ', 'fa', 'cul', 'tad ', 'de', ' in', 'ge', 'nie', 'rí', 'a', ' en ', 'que', ' u', 'na ', 'per', 'so', 'na', ' hi', 'zo', ' u', 'so ', 'de ', 'su ', 'pa', 'se', ' au', 'to', 'má', 'ti', 'co ', 'nú', 'me', 'ro', ' a', 'ños ', 'des', 'pués ', 'de ', 'sa', 'lir ', 'del ', 'ba', 'chi', 'lle', 'ra', 'to.', ' las', ' es', 'ta', 'dís', 'ti', 'cas ', 'de ', 'la', ' u', 'nam ', 'mos', 'tra', 'ban ', 'que', ' e', 'sa ', 'cuan', 'tio', 'sa ', 'po', 'bla', 'ción ', 'de', ' a', 'lum', 'nos', ' i', 'rre', 'gu', 'la', 'res', ' im', 'pli', 'ca', 'ba, ', 'has', 'ta ', 'nú', 'me', 'ro,', ' la', ' e', 'xis', 'ten', 'cia ', 'de ', 'po', 'co ', 'más ', 'de ', 'nú', 'me', 'ro ', 'mil ', 'jó', 've', 'nes ', 'con ', 'to', 'dos', ' e', 'sos ', 'de', 're', 'chos,', ' por', 'que', ' e', 'ran', ' los ', 'que ', 'man', 'te', 'ní', 'an', ' ac', 'ti', 'vi', 'dad', ' ad', 'mi', 'nis', 'tra', 'ti', 'va, ', 'con', ' la ', 'pre', 'sen', 'ta', 'ción ', 'de', ' ex', 'tra', 'or', 'di', 'na', 'rios,', ' has', 'ta ', 'por', ' un ', 'pe', 'rio', 'do ', 'de ', 'nú', 'me', 'ro', ' a', 'ños.', ' pe', 'ro ', 'la ', 'ci', 'fra ', 'se ', 'de', 'tu', 'vo', ' a ', 'par', 'tir ', 'de', ' e', 'se', ' a', 'ño, ', 'cuan', 'do ', 'la ', 'pri', 'me', 'ra ', 'ge', 'ne', 'ra', 'ción', ' a ', 'la ', 'que ', 'se', ' a', 'pli', 'có', ' el ', 'pa', 'se ', 're', 'gla', 'men', 'ta', 'do ', 'con', 'clu', 'yó', ' el ', 'ba', 'chi', 'lle', 'ra', 'to,', ' y', ' a ', 'par', 'tir ', 'de', ' a', 'hí ', 'co', 'men', 'zó', ' a ', 'dis', 'mi', 'nuir.', ' des', 'de ', 'nú', 'me', 'ro', ' has', 'ta', ' el', ' a', 'ño ', 'nú', 'me', 'ro ', 'la', ' u', 'nam', ' re', 'gis', 'tró', ' un ', 'to', 'tal ', 'de ', 'nú', 'me', 'ro ', 'mil ', 'nú', 'me', 'ro ', 'jó', 've', 'nes ', 'del ', 'ba', 'chi', 'lle', 'ra', 'to ', 'que ', 'no ', 'con', 'clu', 'ye', 'ron ', 'sus', ' es', 'tu', 'dios', ' en', ' los ', 'tres', ' a', 'ños', ' re', 'gla', 'men', 'ta', 'rios', ' y', ' el', ' a', 'ño', ' a', 'di', 'cio', 'nal;', ' la', ' a', 'pli', 'ca', 'ción ', 'de ', 'las', ' re', 'glas ', 'per', 'mi', 'tió ', 'que', ' ac', 'tual', 'men', 'te ', 'só', 'lo', ' e', 'xis', 'tan ', 'nú', 'me', 'ro ', 'mil ', 'nú', 'me', 'ro ', 'jó', 've', 'nes', ' en', ' e', 'sa ', 'con', 'di', 'ción,', ' pe', 'ro ', 'seis ', 'mil ', 'nú', 'me', 'ro ', 'ya ', 'no ', 'ten', 'drán ', 'de', 're', 'cho ', 'ni ', 'si', 'quie', 'ra', ' a', ' e', 'xá', 'me', 'nes', ' ex', 'tra', 'or', 'di', 'na', 'rios,', ' por', ' re', 'ba', 'sar', ' el ', 'pe', 'rio', 'do ', 'de', ' a', 'po', 'yo.', ' en', ' el ', 'ca', 'so ', 'de ', 'la ', 'li', 'cen', 'cia', 'tu', 'ra, ', 'des', 'de ', 'nú', 'me', 'ro', ' has', 'ta', ' el ', 'ci', 'clo ', 'nú', 'me', 'ro-', 'nú', 'me', 'ro,', ' la', ' u', 'nam ', 'tu', 'vo', ' un', ' a', 'cu', 'mu', 'la', 'do ', 'de ', 'nú', 'me', 'ro ', 'mil ', 'nú', 'me', 'ro ', 'jó', 've', 'nes ', 'que ', 'no ', 'con', 'clu', 'ye', 'ron', ' la ', 'ca', 'rre', 'ra', ' en', ' los ', 'tiem', 'po', ' es', 'ta', 'ble', 'ci', 'dos;', ' sin', ' em', 'bar', 'go, ', 'nú', 'me', 'ro ', 'mil ', 'nú', 'me', 'ro ', 'ya ', 'per', 'die', 'ron ', 'to', 'dos ', 'sus ', 'de', 're', 'chos,', ' in', 'clu', 'so', ' a ', 'ter', 'mi', 'nar', ' la ', 'ca', 'rre', 'ra ', 'con', ' e', 'xá', 'me', 'nes', ' ex', 'tra', 'or', 'di', 'na', 'rios,', ' por', 'que ', 'ya ', 're', 'ba', 'sa', 'ron', ' el ', 'do', 'ble ', 'del ', 'tiem', 'po ', 'de ', 'du', 'ra', 'ción', ' or', 'di', 'na', 'ria ', 'de ', 'su ', 'li', 'cen', 'cia', 'tu', 'ra ', 'pa', 'ra ', 'ter', 'mi', 'nar', 'la, ', 'con', ' lo ', 'cual', ' ac', 'tual', 'men', 'te ', 'só', 'lo ', 'nú', 'me', 'ro ', 'mil ', 'nú', 'me', 'ro ', 'jó', 've', 'nes ', 'tie', 'nen ', 'vi', 'vos ', 'sus ', 'de', 're', 'chos,', ' pe', 'ro', ' al ', 'me', 'nos ', 'tres ', 'mil ', 'nú', 'me', 'ro ', 'los ', 'per', 'de', 'rán ', 'si ', 'no ', 'con', 'clu', 'ye', 'ron', ' en', ' es', 'te', ' a', 'ño.', ' es ', 'de', 'cir,', ' que ', 'del', ' a', 'cu', 'mu', 'la', 'do ', 'de ', 'nú', 'me', 'ro ', 'mil ', 'jó', 've', 'nes ', 'que', ' has', 'ta', ' el ', 'nú', 'me', 'ro ', 'tu', 'vie', 'ron ', 'vi', 'vos ', 'to', 'dos ', 'sus ', 'de', 're', 'chos ', 'co', 'mo', ' es', 'tu', 'dian', 'tes,', ' a ', 'pe', 'sar ', 'de ', 're', 'pro', 'bar', ' u', 'na ', 'y', ' o', 'tra ', 'vez,', ' a', 'ho', 'ra ', 'só', 'lo ', 'nú', 'me', 'ro ', 'mil ', 'nú', 'me', 'ro', ' es', 'tán', ' en', ' e', 'sas ', 'cir', 'cuns', 'tan', 'cias', ' y', ' a', 'ño ', 'con', ' a', 'ño ', 'la ', 'ci', 'fra ', 'va', 'rí', 'a, ', 'por', 'que ', 'la', ' ins', 'ti', 'tu', 'ción', ' a', 'van', 'za', ' en', ' los ', 'me', 'jo', 'res', ' re', 'sul', 'ta', 'dos ', 'de ', 'su', ' e', 'fi', 'cien', 'cia ', 'ter', 'mi', 'nal.'], 2464)\n"
     ]
    }
   ],
   "source": [
    "print(syllables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2464"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_syllables = syllables[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = ((0.39 * n_words) / n_sents) + ((11.8 * n_syllables) / n_words) - 15.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = (0.39 * len(text.split()) / len(text.split('.')) ) + 11.8 * ( sum(list(map(lambda x: 1 if x in [\"a\",\"i\",\"e\",\"o\",\"u\",\"y\",\"A\",\"E\",\"I\",\"O\",\"U\",\"y\"] else 0,text))) / len(text.split())) - 15.59"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "553 13 1048 42.54 1.9 49.45\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk import word_tokenize, sent_tokenize  \n",
    "from string import punctuation\n",
    "from lexical_diversity import lex_div as ld\n",
    "\n",
    "nlp = spacy.load('es_core_news_lg')\n",
    "\n",
    "text = re.sub(r\"http\\S+\", \"\", text)\n",
    "text = re.sub(r\"@\\S+\", \"\", text)\n",
    "text = re.sub(\"\\n\", \" \", text)\n",
    "text = re.sub(r\"(?<!\\n)\\n(?!\\n)\", \" \", text)\n",
    "text = text.replace(r\"*NUMBER*\", \"número\")\n",
    "text = text.replace(r\"*PHONE*\", \"número\")\n",
    "text = text.replace(r\"*EMAIL*\", \"email\")\n",
    "text = text.replace(r\"*URL*\", \"url\")\n",
    "text = text.lower()\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "syllables= syllabize(text)\n",
    "list_tokens = []\n",
    "list_tags = []\n",
    "list_entities = []\n",
    "n_sents = 0\n",
    "\n",
    "for entity in doc.ents:\n",
    "    list_entities.append(entity.label_)\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    n_sents += 1\n",
    "    for token in sentence:\n",
    "        list_tokens.append(token.text)\n",
    "        list_tags.append(token.pos_)\n",
    "        \n",
    "n_entities = len(list_entities)\n",
    "n_tags = nltk.Counter(list_tags)\n",
    "fdist = FreqDist(list_tokens)\n",
    "n_syllables = syllables[-1]\n",
    "n_words = len(list_tokens)\n",
    "        \n",
    "# complexity features\n",
    "avg_word_sentence = round(n_words / n_sents, 2)\n",
    "avg_word_size = round(sum(len(word) for word in list_tokens) / n_words, 2)\n",
    "avg_syllables_word = round(n_syllables / n_words, 2)\n",
    "unique_words = round((len(fdist.hapaxes()) / n_words) * 100, 2)\n",
    "ttr = round(ld.ttr(list_tokens) * 100, 2)\n",
    "mltd = round(ld.mtld(list_tokens), 2)\n",
    "\n",
    "# readability spanish test\n",
    "i_fernandez_huerta = round(206.84 - (60 * avg_syllables_word) - (1.02 * avg_word_sentence), 2)\n",
    "\n",
    "# stylometric features\n",
    "entity_ratio = (n_entities / n_words) * 100\n",
    "propn_ratio = (n_tags['PROPN'] / n_words) * 100 \n",
    "noun_ratio = (n_tags['NOUN'] / n_words) * 100 \n",
    "adp_ratio = (n_tags['ADP'] / n_words) * 100\n",
    "det_ratio = (n_tags['DET'] / n_words) * 100\n",
    "punct_ratio = (n_tags['PUNCT'] / n_words) * 100 \n",
    "pron_ratio = (n_tags['PRON'] / n_words) * 100\n",
    "verb_ratio = (n_tags['VERB'] / n_words) * 100\n",
    "adv_ratio = (n_tags['ADV'] / n_words) * 100\n",
    "\n",
    "print(n_words, n_sents, n_syllables, avg_word_sentences, avg_syllables_word, i_fernandez_huerta)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply it to the full corpus with iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 11s, sys: 1.52 s, total: 1min 12s\n",
      "Wall time: 1min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lexical_diversity import lex_div as ld\n",
    "nlp = spacy.load('es_core_news_lg')\n",
    "\n",
    "df = pd.read_csv('../data/corpus_spanish.csv')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "df['Label'] = labelencoder.fit_transform(df['Category'])\n",
    "\n",
    "# empty lists and df\n",
    "df_features = pd.DataFrame()\n",
    "list_text = []\n",
    "list_nsentences = []\n",
    "list_nwords = []\n",
    "list_words_sent = []\n",
    "list_word_size = []\n",
    "list_unique_words = []\n",
    "list_ttr = []\n",
    "list_mltd = []\n",
    "list_entity_ratio = []\n",
    "list_nquotes = []\n",
    "list_quotes_ratio = []\n",
    "list_propn_ratio = [] \n",
    "list_noun_ratio = []\n",
    "list_adp_ratio = []\n",
    "list_det_ratio = []\n",
    "list_punct_ratio = []\n",
    "list_pron_ratio = []\n",
    "list_verb_ratio = []\n",
    "list_adv_ratio = []\n",
    "list_sym_ratio = []\n",
    "\n",
    "list_headline = []\n",
    "list_words_h = []\n",
    "list_word_size_h = []\n",
    "list_ttr_h = []\n",
    "list_mltd_h = []\n",
    "list_unique_words_h = []\n",
    "\n",
    "# df iteration\n",
    "for n, row in df.iterrows():\n",
    "    \n",
    "    ## headline ##\n",
    "    text_h = df['Headline'].iloc[n]\n",
    "    text_h = text_h.replace(r\"http\\S+\", \"\")\n",
    "    text_h = text_h.replace(r\"http\", \"\")\n",
    "    text_h = text_h.replace(r\"@\\S+\", \"\")\n",
    "    text_h = text_h.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "    text_h = text_h.lower()\n",
    "    doc_h = nlp(text_h)\n",
    "\n",
    "    list_tokens_h = []\n",
    "    list_tags_h = []\n",
    "    n_sents_h = 0\n",
    "\n",
    "    for sentence_h in doc_h.sents:\n",
    "        n_sents_h += 1\n",
    "        for token in sentence_h:\n",
    "            list_tokens_h.append(token.text)\n",
    "\n",
    "    fdist_h = FreqDist(list_tokens_h)\n",
    "    \n",
    "    # headline complexity features\n",
    "    n_words_h = len(list_tokens_h)\n",
    "    word_size_h = sum(len(word) for word in list_tokens_h) / n_words_h\n",
    "    unique_words_h = (len(fdist_h.hapaxes()) / n_words_h) * 100\n",
    "    ttr_h = ld.ttr(list_tokens_h) * 100\n",
    "    mltd_h = ld.mtld(list_tokens_h)\n",
    "    \n",
    "    ## text content##   \n",
    "    text = df['Text'].iloc[n]  \n",
    "    text = text.replace(r\"http\\S+\", \"\")\n",
    "    text = text.replace(r\"http\", \"\")\n",
    "    text = text.replace(r\"@\\S+\", \"\")\n",
    "    text = text.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "\n",
    "    list_tokens = []\n",
    "    list_pos = []\n",
    "    list_tag = []\n",
    "    list_entities = []\n",
    "    n_sents = 0\n",
    "    \n",
    "    for entity in doc.ents:\n",
    "        list_entities.append(entity.label_)\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        n_sents += 1\n",
    "        for token in sentence:\n",
    "            list_tokens.append(token.text)\n",
    "            list_pos.append(token.pos_)\n",
    "            list_tag.append(token.tag_)\n",
    "    \n",
    "    n_entities = len(list_entities)\n",
    "    n_pos = nltk.Counter(list_pos)\n",
    "    n_tag = nltk.Counter(list_tag)\n",
    "    fdist = FreqDist(list_tokens)\n",
    "\n",
    "    # complexity features\n",
    "    n_words = len(list_tokens)\n",
    "    avg_word_sentences = (float(n_words) / n_sents)\n",
    "    word_size = sum(len(word) for word in list_tokens) / n_words\n",
    "    unique_words = (len(fdist.hapaxes()) / n_words) * 100\n",
    "    ttr = ld.ttr(list_tokens) * 100\n",
    "    mltd = ld.mtld(list_tokens)\n",
    "\n",
    "    # stylometric features\n",
    "    entity_ratio = (n_entities / n_words) * 100\n",
    "    n_quotes = n_tag['PUNCT__PunctType=Quot']\n",
    "    quotes_ratio = (n_quotes / n_words) * 100\n",
    "    propn_ratio = (n_pos['PROPN'] / n_words) * 100 \n",
    "    noun_ratio = (n_pos['NOUN'] / n_words) * 100 \n",
    "    adp_ratio = (n_pos['ADP'] / n_words) * 100\n",
    "    det_ratio = (n_pos['DET'] / n_words) * 100\n",
    "    punct_ratio = (n_pos['PUNCT'] / n_words) * 100 \n",
    "    pron_ratio = (n_pos['PRON'] / n_words) * 100\n",
    "    verb_ratio = (n_pos['VERB'] / n_words) * 100\n",
    "    adv_ratio = (n_pos['ADV'] / n_words) * 100\n",
    "    sym_ratio = (n_tag['SYM'] / n_words) * 100\n",
    "    \n",
    "    # appending on lists\n",
    "    list_text.append(text)\n",
    "    list_nsentences.append(n_sents)\n",
    "    list_nwords.append(n_words)\n",
    "    list_words_sent.append(avg_word_sentences)\n",
    "    list_word_size.append(word_size)\n",
    "    list_unique_words.append(unique_words)\n",
    "    list_ttr.append(ttr)\n",
    "    list_mltd.append(mltd)\n",
    "    list_headline.append(text_h)\n",
    "    list_words_h.append(n_words_h)\n",
    "    list_word_size_h.append(word_size_h)\n",
    "    list_unique_words_h.append(unique_words_h)\n",
    "    list_ttr_h.append(ttr_h)\n",
    "    list_mltd_h.append(mltd_h)\n",
    "    list_entity_ratio.append(entity_ratio)\n",
    "    list_nquotes.append(n_quotes)\n",
    "    list_quotes_ratio.append(quotes_ratio)\n",
    "    list_propn_ratio.append(propn_ratio)\n",
    "    list_noun_ratio.append(noun_ratio)\n",
    "    list_adp_ratio.append(adp_ratio)\n",
    "    list_det_ratio.append(det_ratio)\n",
    "    list_punct_ratio.append(punct_ratio)\n",
    "    list_pron_ratio.append(pron_ratio)\n",
    "    list_verb_ratio.append(verb_ratio)\n",
    "    list_adv_ratio.append(adv_ratio)\n",
    "    list_sym_ratio.append(sym_ratio)\n",
    "    \n",
    "# dataframe\n",
    "df_features['text'] = list_text\n",
    "df_features['headline'] = list_headline\n",
    "df_features['n_sents'] = list_nsentences\n",
    "df_features['n_words'] = list_nwords\n",
    "df_features['avg_words_sents'] = list_words_sent\n",
    "df_features['word_size'] = list_word_size\n",
    "df_features['unique_words'] = list_unique_words\n",
    "df_features['ttr'] = list_ttr\n",
    "df_features['mltd'] = list_mltd\n",
    "df_features['n_words_h'] = list_words_h\n",
    "df_features['word_size_h'] = list_word_size_h\n",
    "df_features['unique_words_h'] = list_unique_words_h\n",
    "df_features['ttr_h'] = list_ttr_h\n",
    "df_features['mltd_h'] = list_mltd_h\n",
    "df_features['entity_ratio'] = list_entity_ratio\n",
    "df_features['n_quotes'] = list_nquotes\n",
    "df_features['quotes_ratio'] = list_quotes_ratio\n",
    "df_features['propn_ratio'] = list_propn_ratio\n",
    "df_features['noun_ratio'] = list_noun_ratio\n",
    "df_features['adp_ratio'] = list_adp_ratio\n",
    "df_features['det_ratio'] = list_det_ratio\n",
    "df_features['punct_ratio'] = list_punct_ratio\n",
    "df_features['pron_ratio'] = list_pron_ratio\n",
    "df_features['verb_ratio'] = list_verb_ratio\n",
    "df_features['adv_ratio'] = list_adv_ratio\n",
    "df_features['sym_ratio'] = list_sym_ratio\n",
    "df_features['label'] = df['Label']\n",
    "\n",
    "df_features.to_csv('../data/spanish_corpus_features_v4.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>headline</th>\n",
       "      <th>n_sents</th>\n",
       "      <th>n_words</th>\n",
       "      <th>avg_words_sents</th>\n",
       "      <th>word_size</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>ttr</th>\n",
       "      <th>mltd</th>\n",
       "      <th>n_words_h</th>\n",
       "      <th>...</th>\n",
       "      <th>propn_ratio</th>\n",
       "      <th>noun_ratio</th>\n",
       "      <th>adp_ratio</th>\n",
       "      <th>det_ratio</th>\n",
       "      <th>punct_ratio</th>\n",
       "      <th>pron_ratio</th>\n",
       "      <th>verb_ratio</th>\n",
       "      <th>adv_ratio</th>\n",
       "      <th>sym_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sofía castro y alejandro peña pretelini: una i...</td>\n",
       "      <td>sofía castro y alejandro peña pretelini: una i...</td>\n",
       "      <td>8</td>\n",
       "      <td>252</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>4.190476</td>\n",
       "      <td>34.920635</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>58.600559</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>15.079365</td>\n",
       "      <td>15.079365</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>11.507937</td>\n",
       "      <td>9.523810</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>6.349206</td>\n",
       "      <td>3.174603</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>un paso más cerca de hacer los exámenes 'onlin...</td>\n",
       "      <td>un paso más cerca de hacer los exámenes 'online'</td>\n",
       "      <td>9</td>\n",
       "      <td>486</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4.255144</td>\n",
       "      <td>32.716049</td>\n",
       "      <td>44.238683</td>\n",
       "      <td>41.283136</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>15.226337</td>\n",
       "      <td>12.345679</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>18.930041</td>\n",
       "      <td>1.234568</td>\n",
       "      <td>3.292181</td>\n",
       "      <td>1.646091</td>\n",
       "      <td>1.851852</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>esto es lo que los científicos realmente piens...</td>\n",
       "      <td>esto es lo que los científicos realmente piens...</td>\n",
       "      <td>31</td>\n",
       "      <td>980</td>\n",
       "      <td>31.612903</td>\n",
       "      <td>4.815306</td>\n",
       "      <td>26.020408</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>80.551467</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4.795918</td>\n",
       "      <td>17.857143</td>\n",
       "      <td>13.979592</td>\n",
       "      <td>12.755102</td>\n",
       "      <td>11.836735</td>\n",
       "      <td>2.551020</td>\n",
       "      <td>10.306122</td>\n",
       "      <td>4.693878</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inicia impresión de boletas para elección pres...</td>\n",
       "      <td>inicia impresión de boletas para elección pres...</td>\n",
       "      <td>11</td>\n",
       "      <td>369</td>\n",
       "      <td>33.545455</td>\n",
       "      <td>4.728997</td>\n",
       "      <td>22.764228</td>\n",
       "      <td>37.398374</td>\n",
       "      <td>50.995314</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>4.065041</td>\n",
       "      <td>22.493225</td>\n",
       "      <td>18.157182</td>\n",
       "      <td>15.176152</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>2.710027</td>\n",
       "      <td>7.317073</td>\n",
       "      <td>0.271003</td>\n",
       "      <td>1.355014</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a *number* día del mundial\\nfifa.com sigue la ...</td>\n",
       "      <td>a *number* día del mundial</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.461538</td>\n",
       "      <td>48.461538</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>47.081602</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>14.615385</td>\n",
       "      <td>14.615385</td>\n",
       "      <td>17.692308</td>\n",
       "      <td>13.846154</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interpol ordena detención inmediata de osorio ...</td>\n",
       "      <td>interpol ordena detención inmediata de osorio ...</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.793103</td>\n",
       "      <td>48.275862</td>\n",
       "      <td>63.793103</td>\n",
       "      <td>63.025950</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>12.068966</td>\n",
       "      <td>16.379310</td>\n",
       "      <td>18.965517</td>\n",
       "      <td>12.931034</td>\n",
       "      <td>12.068966</td>\n",
       "      <td>2.586207</td>\n",
       "      <td>5.172414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"los ninis\" más ricos y poderosos del país: hi...</td>\n",
       "      <td>\"los ninis\" más ricos y poderosos del país: hi...</td>\n",
       "      <td>5</td>\n",
       "      <td>211</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>3.668246</td>\n",
       "      <td>35.071090</td>\n",
       "      <td>50.236967</td>\n",
       "      <td>50.913142</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>6.635071</td>\n",
       "      <td>16.113744</td>\n",
       "      <td>11.848341</td>\n",
       "      <td>11.374408</td>\n",
       "      <td>9.004739</td>\n",
       "      <td>2.369668</td>\n",
       "      <td>6.161137</td>\n",
       "      <td>5.687204</td>\n",
       "      <td>0.473934</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>para todo sacan lo del populismo, ni siquiera ...</td>\n",
       "      <td>gobierno de alfredo del mazo inició con récord...</td>\n",
       "      <td>12</td>\n",
       "      <td>416</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>4.139423</td>\n",
       "      <td>32.932692</td>\n",
       "      <td>46.875000</td>\n",
       "      <td>66.856042</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6.009615</td>\n",
       "      <td>17.067308</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>9.855769</td>\n",
       "      <td>12.980769</td>\n",
       "      <td>4.807692</td>\n",
       "      <td>10.576923</td>\n",
       "      <td>2.403846</td>\n",
       "      <td>0.480769</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conapred investiga acto de racismo en el pumas...</td>\n",
       "      <td>conapred investiga acto de racismo en el pumas...</td>\n",
       "      <td>6</td>\n",
       "      <td>227</td>\n",
       "      <td>37.833333</td>\n",
       "      <td>4.101322</td>\n",
       "      <td>35.682819</td>\n",
       "      <td>51.541850</td>\n",
       "      <td>66.635851</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10.572687</td>\n",
       "      <td>15.859031</td>\n",
       "      <td>13.656388</td>\n",
       "      <td>11.013216</td>\n",
       "      <td>13.215859</td>\n",
       "      <td>3.083700</td>\n",
       "      <td>9.251101</td>\n",
       "      <td>2.643172</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cristiano ronaldo acepta dos años de prisión\\n...</td>\n",
       "      <td>cristiano ronaldo acepta dos años de prisión</td>\n",
       "      <td>17</td>\n",
       "      <td>590</td>\n",
       "      <td>34.705882</td>\n",
       "      <td>4.276271</td>\n",
       "      <td>24.576271</td>\n",
       "      <td>35.932203</td>\n",
       "      <td>46.584855</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.084746</td>\n",
       "      <td>17.966102</td>\n",
       "      <td>14.237288</td>\n",
       "      <td>12.711864</td>\n",
       "      <td>10.677966</td>\n",
       "      <td>1.864407</td>\n",
       "      <td>8.474576</td>\n",
       "      <td>3.050847</td>\n",
       "      <td>2.372881</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  sofía castro y alejandro peña pretelini: una i...   \n",
       "1  un paso más cerca de hacer los exámenes 'onlin...   \n",
       "2  esto es lo que los científicos realmente piens...   \n",
       "3  inicia impresión de boletas para elección pres...   \n",
       "4  a *number* día del mundial\\nfifa.com sigue la ...   \n",
       "5  interpol ordena detención inmediata de osorio ...   \n",
       "6  \"los ninis\" más ricos y poderosos del país: hi...   \n",
       "7  para todo sacan lo del populismo, ni siquiera ...   \n",
       "8  conapred investiga acto de racismo en el pumas...   \n",
       "9  cristiano ronaldo acepta dos años de prisión\\n...   \n",
       "\n",
       "                                            headline  n_sents  n_words  \\\n",
       "0  sofía castro y alejandro peña pretelini: una i...        8      252   \n",
       "1   un paso más cerca de hacer los exámenes 'online'        9      486   \n",
       "2  esto es lo que los científicos realmente piens...       31      980   \n",
       "3  inicia impresión de boletas para elección pres...       11      369   \n",
       "4                         a *number* día del mundial        5      130   \n",
       "5  interpol ordena detención inmediata de osorio ...        4      116   \n",
       "6  \"los ninis\" más ricos y poderosos del país: hi...        5      211   \n",
       "7  gobierno de alfredo del mazo inició con récord...       12      416   \n",
       "8  conapred investiga acto de racismo en el pumas...        6      227   \n",
       "9       cristiano ronaldo acepta dos años de prisión       17      590   \n",
       "\n",
       "   avg_words_sents  word_size  unique_words        ttr       mltd  n_words_h  \\\n",
       "0        31.500000   4.190476     34.920635  50.000000  58.600559         12   \n",
       "1        54.000000   4.255144     32.716049  44.238683  41.283136         11   \n",
       "2        31.612903   4.815306     26.020408  38.571429  80.551467         12   \n",
       "3        33.545455   4.728997     22.764228  37.398374  50.995314          7   \n",
       "4        26.000000   4.461538     48.461538  60.000000  47.081602          7   \n",
       "5        29.000000   4.793103     48.275862  63.793103  63.025950         13   \n",
       "6        42.200000   3.668246     35.071090  50.236967  50.913142         14   \n",
       "7        34.666667   4.139423     32.932692  46.875000  66.856042         11   \n",
       "8        37.833333   4.101322     35.682819  51.541850  66.635851         10   \n",
       "9        34.705882   4.276271     24.576271  35.932203  46.584855          7   \n",
       "\n",
       "   ...  propn_ratio  noun_ratio  adp_ratio  det_ratio  punct_ratio  \\\n",
       "0  ...    15.079365   15.079365  13.888889  11.507937     9.523810   \n",
       "1  ...    16.666667   15.226337  12.345679  11.111111    18.930041   \n",
       "2  ...     4.795918   17.857143  13.979592  12.755102    11.836735   \n",
       "3  ...     4.065041   22.493225  18.157182  15.176152    11.111111   \n",
       "4  ...    14.615385   14.615385  17.692308  13.846154     9.230769   \n",
       "5  ...    12.068966   16.379310  18.965517  12.931034    12.068966   \n",
       "6  ...     6.635071   16.113744  11.848341  11.374408     9.004739   \n",
       "7  ...     6.009615   17.067308  15.625000   9.855769    12.980769   \n",
       "8  ...    10.572687   15.859031  13.656388  11.013216    13.215859   \n",
       "9  ...     5.084746   17.966102  14.237288  12.711864    10.677966   \n",
       "\n",
       "   pron_ratio  verb_ratio  adv_ratio  sym_ratio  label  \n",
       "0    5.555556    6.349206   3.174603   0.000000      1  \n",
       "1    1.234568    3.292181   1.646091   1.851852      1  \n",
       "2    2.551020   10.306122   4.693878   0.510204      1  \n",
       "3    2.710027    7.317073   0.271003   1.355014      1  \n",
       "4    3.076923    4.615385   1.538462   2.307692      1  \n",
       "5    2.586207    5.172414   0.000000   0.862069      0  \n",
       "6    2.369668    6.161137   5.687204   0.473934      0  \n",
       "7    4.807692   10.576923   2.403846   0.480769      1  \n",
       "8    3.083700    9.251101   2.643172   0.000000      1  \n",
       "9    1.864407    8.474576   3.050847   2.372881      1  \n",
       "\n",
       "[10 rows x 27 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
