{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the datasets\n",
    "\n",
    "1) Load the dataset, unify it and shuffle it.\n",
    "\n",
    "3) Explore texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk import word_tokenize\n",
    "from nltk import sent_tokenize\n",
    "from nltk.data import load  \n",
    "from nltk.stem import SnowballStemmer  \n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('~/TFM_fake_news_detector/data/corpus_spanish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 971 entries, 0 to 970\n",
      "Data columns (total 7 columns):\n",
      "Id          971 non-null int64\n",
      "Category    971 non-null object\n",
      "Topic       971 non-null object\n",
      "Source      971 non-null object\n",
      "Headline    971 non-null object\n",
      "Text        971 non-null object\n",
      "Link        971 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 53.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = df_cleaned['Text'].iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641</td>\n",
       "      <td>True</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Caras</td>\n",
       "      <td>Sofía Castro y Alejandro Peña Pretelini: una i...</td>\n",
       "      <td>sofía castro y alejandro peña pretelini: una i...</td>\n",
       "      <td>https://www.caras.com.mx/sofia-castro-alejandr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Education</td>\n",
       "      <td>Heraldo</td>\n",
       "      <td>Un paso más cerca de hacer los exámenes 'online'</td>\n",
       "      <td>un paso más cerca de hacer los exámenes 'onlin...</td>\n",
       "      <td>https://www.heraldo.es/noticias/suplementos/he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141</td>\n",
       "      <td>True</td>\n",
       "      <td>Science</td>\n",
       "      <td>HUFFPOST</td>\n",
       "      <td>Esto es lo que los científicos realmente piens...</td>\n",
       "      <td>esto es lo que los científicos realmente piens...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394</td>\n",
       "      <td>True</td>\n",
       "      <td>Politics</td>\n",
       "      <td>El financiero</td>\n",
       "      <td>Inicia impresión de boletas para elección pres...</td>\n",
       "      <td>inicia impresión de boletas para elección pres...</td>\n",
       "      <td>http://www.elfinanciero.com.mx/elecciones-2018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139</td>\n",
       "      <td>True</td>\n",
       "      <td>Sport</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>A *NUMBER* día del Mundial</td>\n",
       "      <td>a *number* día del mundial fifa.com sigue la c...</td>\n",
       "      <td>https://es.fifa.com/worldcup/news/a-1-dia-del-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Category          Topic         Source  \\\n",
       "0  641     True  Entertainment          Caras   \n",
       "1    6     True      Education        Heraldo   \n",
       "2  141     True        Science       HUFFPOST   \n",
       "3  394     True       Politics  El financiero   \n",
       "4  139     True          Sport           FIFA   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  Sofía Castro y Alejandro Peña Pretelini: una i...   \n",
       "1   Un paso más cerca de hacer los exámenes 'online'   \n",
       "2  Esto es lo que los científicos realmente piens...   \n",
       "3  Inicia impresión de boletas para elección pres...   \n",
       "4                         A *NUMBER* día del Mundial   \n",
       "\n",
       "                                                Text  \\\n",
       "0  sofía castro y alejandro peña pretelini: una i...   \n",
       "1  un paso más cerca de hacer los exámenes 'onlin...   \n",
       "2  esto es lo que los científicos realmente piens...   \n",
       "3  inicia impresión de boletas para elección pres...   \n",
       "4  a *number* día del mundial fifa.com sigue la c...   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.caras.com.mx/sofia-castro-alejandr...  \n",
       "1  https://www.heraldo.es/noticias/suplementos/he...  \n",
       "2  https://www.huffingtonpost.com/entry/scientist...  \n",
       "3  http://www.elfinanciero.com.mx/elecciones-2018...  \n",
       "4  https://es.fifa.com/worldcup/news/a-1-dia-del-...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize_text(df, text_field):\n",
    "    \n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    \n",
    "    return df\n",
    "df_cleaned = standardize_text(df, \"Text\")\n",
    "\n",
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average words per sentence and nº of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cristiano', 'ronaldo', 'acepta', 'dos', 'años', 'prisión', 'luso', 'acuerdo', 'verbal', 'fiscalía', 'madrid', 'tras', 'admitir', 'cuatro', 'delitos', 'fiscales']\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"¡cristiano ronaldo acepta dos años de prisión! el luso tiene un acuerdo verbal con la fiscalía de madrid tras admitir cuatro delitos fiscales\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "\n",
    "stop_words = stopwords.words('spanish')\n",
    "filtered_tokens = [w for w in tokens if w not in stop_words]\n",
    "print(filtered_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average words per sentence is: 28.000000\n"
     ]
    }
   ],
   "source": [
    "# count number of sentences\n",
    "sent_tokens = nltk.sent_tokenize(text1)\n",
    "number_sentences = len(sent_tokens)\n",
    "\n",
    "# count number of words\n",
    "word_tokens = nltk.word_tokenize(text1) \n",
    "\n",
    "# need to take out commas plus other stuff\n",
    "stop_words = stopwords.words('spanish')\n",
    "stop_words.extend(list(punctuation))\n",
    "stop_words.extend(['¿', '¡', '\"', '``']) \n",
    "stop_words.extend(map(str,range(10)))\n",
    "\n",
    "# number of words\n",
    "filtered_tokens = [i for i in word_tokens if i not in stop_words]\n",
    "number_words = len(filtered_tokens)\n",
    "\n",
    "# average sentence length are words divided by sentences\n",
    "print('The average words per sentence is: %f' %(float(number_words)/number_sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average size words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of sentences are: 8\n",
      "The average words per sentence is: 28.000000\n",
      "The average word size is: 7\n",
      "The type token ratio is: 76\n"
     ]
    }
   ],
   "source": [
    "# count number of sentences\n",
    "sent_tokens = nltk.sent_tokenize(text1)\n",
    "number_sentences = len(sent_tokens)\n",
    "\n",
    "# count number of words\n",
    "word_tokens = nltk.word_tokenize(text1) \n",
    "\n",
    "# need to take out commas plus other stuff\n",
    "stop_words = stopwords.words('spanish')\n",
    "stop_words.extend(list(punctuation))\n",
    "stop_words.extend(['¿', '¡', '\"', '``']) \n",
    "stop_words.extend(map(str,range(10)))\n",
    "\n",
    "# number of words\n",
    "filtered_tokens = [i for i in word_tokens if i not in stop_words]\n",
    "number_words = len(filtered_tokens)\n",
    "\n",
    "# number of characters\n",
    "avg_word_size = sum(len(word) for word in filtered_tokens)/number_words\n",
    "\n",
    "# type token ratio\n",
    "types = nltk.Counter(filtered_tokens)\n",
    "TTR = (len(types) / number_words) * 100\n",
    "\n",
    "print('The number of sentences are: %d' %(number_sentences))\n",
    "print('The average words per sentence is: %f' %(float(number_words)/number_sentences))\n",
    "print('The average word size is: %d' %(avg_word_size))\n",
    "print('The type token ratio is: %d' %(TTR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641</td>\n",
       "      <td>True</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Caras</td>\n",
       "      <td>Sofía Castro y Alejandro Peña Pretelini: una i...</td>\n",
       "      <td>sofía castro y alejandro peña pretelini: una i...</td>\n",
       "      <td>https://www.caras.com.mx/sofia-castro-alejandr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Education</td>\n",
       "      <td>Heraldo</td>\n",
       "      <td>Un paso más cerca de hacer los exámenes 'online'</td>\n",
       "      <td>un paso más cerca de hacer los exámenes 'onlin...</td>\n",
       "      <td>https://www.heraldo.es/noticias/suplementos/he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141</td>\n",
       "      <td>True</td>\n",
       "      <td>Science</td>\n",
       "      <td>HUFFPOST</td>\n",
       "      <td>Esto es lo que los científicos realmente piens...</td>\n",
       "      <td>esto es lo que los científicos realmente piens...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394</td>\n",
       "      <td>True</td>\n",
       "      <td>Politics</td>\n",
       "      <td>El financiero</td>\n",
       "      <td>Inicia impresión de boletas para elección pres...</td>\n",
       "      <td>inicia impresión de boletas para elección pres...</td>\n",
       "      <td>http://www.elfinanciero.com.mx/elecciones-2018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139</td>\n",
       "      <td>True</td>\n",
       "      <td>Sport</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>A *NUMBER* día del Mundial</td>\n",
       "      <td>a *number* día del mundial fifa.com sigue la c...</td>\n",
       "      <td>https://es.fifa.com/worldcup/news/a-1-dia-del-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Category          Topic         Source  \\\n",
       "0  641     True  Entertainment          Caras   \n",
       "1    6     True      Education        Heraldo   \n",
       "2  141     True        Science       HUFFPOST   \n",
       "3  394     True       Politics  El financiero   \n",
       "4  139     True          Sport           FIFA   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  Sofía Castro y Alejandro Peña Pretelini: una i...   \n",
       "1   Un paso más cerca de hacer los exámenes 'online'   \n",
       "2  Esto es lo que los científicos realmente piens...   \n",
       "3  Inicia impresión de boletas para elección pres...   \n",
       "4                         A *NUMBER* día del Mundial   \n",
       "\n",
       "                                                Text  \\\n",
       "0  sofía castro y alejandro peña pretelini: una i...   \n",
       "1  un paso más cerca de hacer los exámenes 'onlin...   \n",
       "2  esto es lo que los científicos realmente piens...   \n",
       "3  inicia impresión de boletas para elección pres...   \n",
       "4  a *number* día del mundial fifa.com sigue la c...   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.caras.com.mx/sofia-castro-alejandr...  \n",
       "1  https://www.heraldo.es/noticias/suplementos/he...  \n",
       "2  https://www.huffingtonpost.com/entry/scientist...  \n",
       "3  http://www.elfinanciero.com.mx/elecciones-2018...  \n",
       "4  https://es.fifa.com/worldcup/news/a-1-dia-del-...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize_text(df, text_field):\n",
    "    \n",
    "    df[text_field] = df[text_field].str.replace(r\"http\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"http\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"@\\S+\", \"\")\n",
    "    df[text_field] = df[text_field].str.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "    df[text_field] = df[text_field].str.lower()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = standardize_text(df, \"Text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "      <th>sentences</th>\n",
       "      <th>n_words</th>\n",
       "      <th>avg_words_sent</th>\n",
       "      <th>avg_word_size</th>\n",
       "      <th>TTR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641</td>\n",
       "      <td>True</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Caras</td>\n",
       "      <td>Sofía Castro y Alejandro Peña Pretelini: una i...</td>\n",
       "      <td>sofía castro y alejandro peña pretelini: una i...</td>\n",
       "      <td>https://www.caras.com.mx/sofia-castro-alejandr...</td>\n",
       "      <td>5</td>\n",
       "      <td>123</td>\n",
       "      <td>24.600000</td>\n",
       "      <td>6.398374</td>\n",
       "      <td>69.105691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Education</td>\n",
       "      <td>Heraldo</td>\n",
       "      <td>Un paso más cerca de hacer los exámenes 'online'</td>\n",
       "      <td>un paso más cerca de hacer los exámenes 'onlin...</td>\n",
       "      <td>https://www.heraldo.es/noticias/suplementos/he...</td>\n",
       "      <td>8</td>\n",
       "      <td>224</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>7.200893</td>\n",
       "      <td>76.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141</td>\n",
       "      <td>True</td>\n",
       "      <td>Science</td>\n",
       "      <td>HUFFPOST</td>\n",
       "      <td>Esto es lo que los científicos realmente piens...</td>\n",
       "      <td>esto es lo que los científicos realmente piens...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/scientist...</td>\n",
       "      <td>29</td>\n",
       "      <td>467</td>\n",
       "      <td>16.103448</td>\n",
       "      <td>7.571734</td>\n",
       "      <td>64.668094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394</td>\n",
       "      <td>True</td>\n",
       "      <td>Politics</td>\n",
       "      <td>El financiero</td>\n",
       "      <td>Inicia impresión de boletas para elección pres...</td>\n",
       "      <td>inicia impresión de boletas para elección pres...</td>\n",
       "      <td>http://www.elfinanciero.com.mx/elecciones-2018...</td>\n",
       "      <td>10</td>\n",
       "      <td>167</td>\n",
       "      <td>16.700000</td>\n",
       "      <td>7.964072</td>\n",
       "      <td>63.473054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139</td>\n",
       "      <td>True</td>\n",
       "      <td>Sport</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>A *NUMBER* día del Mundial</td>\n",
       "      <td>a *number* día del mundial fifa.com sigue la c...</td>\n",
       "      <td>https://es.fifa.com/worldcup/news/a-1-dia-del-...</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>14.250000</td>\n",
       "      <td>7.368421</td>\n",
       "      <td>84.210526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Category          Topic         Source  \\\n",
       "0  641     True  Entertainment          Caras   \n",
       "1    6     True      Education        Heraldo   \n",
       "2  141     True        Science       HUFFPOST   \n",
       "3  394     True       Politics  El financiero   \n",
       "4  139     True          Sport           FIFA   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  Sofía Castro y Alejandro Peña Pretelini: una i...   \n",
       "1   Un paso más cerca de hacer los exámenes 'online'   \n",
       "2  Esto es lo que los científicos realmente piens...   \n",
       "3  Inicia impresión de boletas para elección pres...   \n",
       "4                         A *NUMBER* día del Mundial   \n",
       "\n",
       "                                                Text  \\\n",
       "0  sofía castro y alejandro peña pretelini: una i...   \n",
       "1  un paso más cerca de hacer los exámenes 'onlin...   \n",
       "2  esto es lo que los científicos realmente piens...   \n",
       "3  inicia impresión de boletas para elección pres...   \n",
       "4  a *number* día del mundial fifa.com sigue la c...   \n",
       "\n",
       "                                                Link  sentences  n_words  \\\n",
       "0  https://www.caras.com.mx/sofia-castro-alejandr...          5      123   \n",
       "1  https://www.heraldo.es/noticias/suplementos/he...          8      224   \n",
       "2  https://www.huffingtonpost.com/entry/scientist...         29      467   \n",
       "3  http://www.elfinanciero.com.mx/elecciones-2018...         10      167   \n",
       "4  https://es.fifa.com/worldcup/news/a-1-dia-del-...          4       57   \n",
       "\n",
       "   avg_words_sent  avg_word_size        TTR  \n",
       "0       24.600000       6.398374  69.105691  \n",
       "1       28.000000       7.200893  76.785714  \n",
       "2       16.103448       7.571734  64.668094  \n",
       "3       16.700000       7.964072  63.473054  \n",
       "4       14.250000       7.368421  84.210526  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('~/TFM_fake_news_detector/data/corpus_spanish.csv')\n",
    "\n",
    "df_cleaned = standardize_text(df, \"Text\")\n",
    "\n",
    "n_sentences = []\n",
    "n_words = []\n",
    "avg_words_sent = []\n",
    "avg_word_size = []\n",
    "type_token_ratio = []\n",
    "\n",
    "for i, row in df_cleaned.iterrows():\n",
    "    text = df['Text'].iloc[i]\n",
    "    \n",
    "    sent_tokens = nltk.sent_tokenize(text)\n",
    "    \n",
    "    #Number of sentences\n",
    "    number_sentences = len(sent_tokens)\n",
    "    \n",
    "    word_tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    stop_words = stopwords.words('spanish')\n",
    "    stop_words.extend(list(punctuation))\n",
    "    stop_words.extend(['¿', '¡', '\"', '``']) \n",
    "    stop_words.extend(map(str,range(10)))\n",
    "    \n",
    "    filtered_tokens = [i for i in word_tokens if i not in stop_words]\n",
    "    \n",
    "    #number of tokens\n",
    "    number_words = len(filtered_tokens)\n",
    "    \n",
    "    # average words per sentence\n",
    "    avg_word_sentences = (float(number_words)/number_sentences)\n",
    "    \n",
    "    # average word size\n",
    "    word_size = sum(len(word) for word in filtered_tokens) / number_words\n",
    "    \n",
    "    # type token ratio\n",
    "    types = nltk.Counter(filtered_tokens)\n",
    "    TTR = (len(types) / number_words) * 100\n",
    "    \n",
    "    n_sentences.append(number_sentences)\n",
    "    n_words.append(number_words)\n",
    "    avg_words_sent.append(avg_word_sentences)\n",
    "    avg_word_size.append(word_size)\n",
    "    type_token_ratio.append(TTR)\n",
    "           \n",
    "df_cleaned['sentences'] = n_sentences\n",
    "df_cleaned['n_words'] = n_words\n",
    "df_cleaned['avg_words_sent'] = avg_words_sent\n",
    "df_cleaned['avg_word_size'] = avg_word_size\n",
    "df_cleaned['TTR'] = type_token_ratio\n",
    "\n",
    "\n",
    "df_features = df_cleaned\n",
    "\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.to_csv('~/TFM_fake_news_detector/data/corpus_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
