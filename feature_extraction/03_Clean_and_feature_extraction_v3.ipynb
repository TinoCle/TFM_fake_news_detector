{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and feature extraction v3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text, extract stylometric features and create a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/corpus_spanish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Source</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Text</th>\n",
       "      <th>Link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>641</td>\n",
       "      <td>True</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>Caras</td>\n",
       "      <td>Sofía Castro y Alejandro Peña Pretelini: una i...</td>\n",
       "      <td>Sofía Castro y Alejandro Peña Pretelini: una i...</td>\n",
       "      <td>https://www.caras.com.mx/sofia-castro-alejandr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>Education</td>\n",
       "      <td>Heraldo</td>\n",
       "      <td>Un paso más cerca de hacer los exámenes 'online'</td>\n",
       "      <td>Un paso más cerca de hacer los exámenes 'onlin...</td>\n",
       "      <td>https://www.heraldo.es/noticias/suplementos/he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141</td>\n",
       "      <td>True</td>\n",
       "      <td>Science</td>\n",
       "      <td>HUFFPOST</td>\n",
       "      <td>Esto es lo que los científicos realmente piens...</td>\n",
       "      <td>Esto es lo que los científicos realmente piens...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/scientist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>394</td>\n",
       "      <td>True</td>\n",
       "      <td>Politics</td>\n",
       "      <td>El financiero</td>\n",
       "      <td>Inicia impresión de boletas para elección pres...</td>\n",
       "      <td>Inicia impresión de boletas para elección pres...</td>\n",
       "      <td>http://www.elfinanciero.com.mx/elecciones-2018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139</td>\n",
       "      <td>True</td>\n",
       "      <td>Sport</td>\n",
       "      <td>FIFA</td>\n",
       "      <td>A *NUMBER* día del Mundial</td>\n",
       "      <td>A *NUMBER* día del Mundial\\nFIFA.com sigue la ...</td>\n",
       "      <td>https://es.fifa.com/worldcup/news/a-1-dia-del-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id Category          Topic         Source  \\\n",
       "0  641     True  Entertainment          Caras   \n",
       "1    6     True      Education        Heraldo   \n",
       "2  141     True        Science       HUFFPOST   \n",
       "3  394     True       Politics  El financiero   \n",
       "4  139     True          Sport           FIFA   \n",
       "\n",
       "                                            Headline  \\\n",
       "0  Sofía Castro y Alejandro Peña Pretelini: una i...   \n",
       "1   Un paso más cerca de hacer los exámenes 'online'   \n",
       "2  Esto es lo que los científicos realmente piens...   \n",
       "3  Inicia impresión de boletas para elección pres...   \n",
       "4                         A *NUMBER* día del Mundial   \n",
       "\n",
       "                                                Text  \\\n",
       "0  Sofía Castro y Alejandro Peña Pretelini: una i...   \n",
       "1  Un paso más cerca de hacer los exámenes 'onlin...   \n",
       "2  Esto es lo que los científicos realmente piens...   \n",
       "3  Inicia impresión de boletas para elección pres...   \n",
       "4  A *NUMBER* día del Mundial\\nFIFA.com sigue la ...   \n",
       "\n",
       "                                                Link  \n",
       "0  https://www.caras.com.mx/sofia-castro-alejandr...  \n",
       "1  https://www.heraldo.es/noticias/suplementos/he...  \n",
       "2  https://www.huffingtonpost.com/entry/scientist...  \n",
       "3  http://www.elfinanciero.com.mx/elecciones-2018...  \n",
       "4  https://es.fifa.com/worldcup/news/a-1-dia-del-...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(971, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id           int64\n",
       "Category    object\n",
       "Topic       object\n",
       "Source      object\n",
       "Headline    object\n",
       "Text        object\n",
       "Link        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 971 entries, 0 to 970\n",
      "Data columns (total 7 columns):\n",
      "Id          971 non-null int64\n",
      "Category    971 non-null object\n",
      "Topic       971 non-null object\n",
      "Source      971 non-null object\n",
      "Headline    971 non-null object\n",
      "Text        971 non-null object\n",
      "Link        971 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 53.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are using `spacy`: The NLP *Ruby on Rails* \n",
    "\n",
    "[spacy](http://www.spacy.io/) is a library of natural language processing, robust, fast, easy to install and to use. It can be used with other NLP and Deep Learning Libraries.\n",
    "\n",
    "With its pre-trained models in spanish language, we can operate the typical NLP jobs: Sentences segmentation, tokenization, POS tag, etc...\n",
    "\n",
    "We are going to use the `es_core_news_lg` pre-trained model to make pos tagging:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the pre trained model in spanish language\n",
    "\n",
    "nlp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sofía Castro y Alejandro Peña Pretelini: una inigualable relación de hermanos\n",
      "La actriz compartió a través de sus redes sociales una tierna imagen con el hijo de Enrique Peña Nieto\n",
      "Los hermanos suelen convertirse en grandes amistades para muchos, esto pasa con Sofía Castro y Alejandro Peña Pretellini, quienes no dudan en compartir la buena amistad que hay entre ellos.\n",
      "A través de sus redes sociales, la actriz de *NUMBER* años compartió una fotografía junto al hijo de Enrique Peña Nieto y la acompañó de un cariñoso mensaje, ?Lo mejor de mi vida?, escribió.\n",
      "El hijo de Enrique Peña Nieto y la hija de Angélica Rivera, más que hermanos, se han convertido en grandes amigos y las fotos que comparten en sus respectivas cuentas en Instagram muestran lo bien que se llevan.\n",
      "Si bien la hija mayor de la primera dama se lleva de maravilla con los tres hijos del esposo de su mamá, la poca diferencia de edad con Alejandro Peña, con quien se lleva sólo un año, hace que los jóvenes se entiendan a la perfección.\n",
      "Alejandro Peña Pretelini es el único hijo varón de Enrique Peña Nieto y Mónica Pretelini, se ha destacado por ser un hermano protector y muy cariñoso, siempre cerca de sus hermanas Paulina y Nicole Peña, tanto de sus hermanastras Sofía, Fernanda y Regina Castro.\n"
     ]
    }
   ],
   "source": [
    "text = df['Text'].iloc[0]\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean text for spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_clean(text):\n",
    "    \n",
    "    text = text.replace(r\"http\\S+\", \"\")\n",
    "    text = text.replace(r\"http\", \"\")\n",
    "    text = text.replace(r\"@\\S+\", \"\")\n",
    "    text = text.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "    text = text.lower()\n",
    "    \n",
    "    # text processing\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = text_clean(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can easily iterate over the sentences list and scroll through the tokens to access their morpho-syntactic information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oración: sofía castro y alejandro peña pretelini: una inigualable relación de hermanos\n",
      "\n",
      "sofía PROPN\n",
      "castro PROPN\n",
      "y CCONJ\n",
      "alejandro PROPN\n",
      "peña PROPN\n",
      "pretelini PROPN\n",
      ": PUNCT\n",
      "una DET\n",
      "inigualable ADJ\n",
      "relación NOUN\n",
      "de ADP\n",
      "hermanos NOUN\n",
      "\n",
      " SPACE\n",
      "Oración: la actriz compartió a través de sus redes sociales una tierna imagen con el hijo de enrique peña nieto\n",
      "\n",
      "la DET\n",
      "actriz NOUN\n",
      "compartió VERB\n",
      "a ADP\n",
      "través INTJ\n",
      "de ADP\n",
      "sus DET\n",
      "redes NOUN\n",
      "sociales ADJ\n",
      "una DET\n",
      "tierna ADJ\n",
      "imagen NOUN\n",
      "con ADP\n",
      "el DET\n",
      "hijo NOUN\n",
      "de ADP\n",
      "enrique PROPN\n",
      "peña PROPN\n",
      "nieto PROPN\n",
      "\n",
      " SPACE\n",
      "Oración: los hermanos suelen convertirse en grandes amistades para muchos, esto pasa con sofía castro y alejandro peña pretellini, quienes no dudan en compartir la buena amistad que hay entre ellos.\n",
      "\n",
      "los DET\n",
      "hermanos NOUN\n",
      "suelen VERB\n",
      "convertirse VERB\n",
      "en ADP\n",
      "grandes ADJ\n",
      "amistades NOUN\n",
      "para ADP\n",
      "muchos PRON\n",
      ", PUNCT\n",
      "esto PRON\n",
      "pasa VERB\n",
      "con ADP\n",
      "sofía PROPN\n",
      "castro PROPN\n",
      "y CCONJ\n",
      "alejandro PROPN\n",
      "peña PROPN\n",
      "pretellini PROPN\n",
      ", PUNCT\n",
      "quienes PRON\n",
      "no ADV\n",
      "dudan AUX\n",
      "en ADP\n",
      "compartir VERB\n",
      "la DET\n",
      "buena ADJ\n",
      "amistad NOUN\n",
      "que SCONJ\n",
      "hay AUX\n",
      "entre ADP\n",
      "ellos PRON\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "Oración: a través de sus redes sociales, la actriz de *number* años compartió una fotografía junto al hijo de enrique peña nieto y la acompañó de un cariñoso mensaje, ?\n",
      "a ADP\n",
      "través INTJ\n",
      "de ADP\n",
      "sus DET\n",
      "redes NOUN\n",
      "sociales ADJ\n",
      ", PUNCT\n",
      "la DET\n",
      "actriz NOUN\n",
      "de ADP\n",
      "* PUNCT\n",
      "number INTJ\n",
      "* PUNCT\n",
      "años NOUN\n",
      "compartió VERB\n",
      "una DET\n",
      "fotografía NOUN\n",
      "junto ADJ\n",
      "al ADP\n",
      "hijo NOUN\n",
      "de ADP\n",
      "enrique PROPN\n",
      "peña PROPN\n",
      "nieto PROPN\n",
      "y CCONJ\n",
      "la PRON\n",
      "acompañó VERB\n",
      "de ADP\n",
      "un DET\n",
      "cariñoso ADJ\n",
      "mensaje NOUN\n",
      ", PUNCT\n",
      "? PUNCT\n",
      "Oración: lo mejor de mi vida?, escribió.\n",
      "\n",
      "lo PRON\n",
      "mejor ADJ\n",
      "de ADP\n",
      "mi DET\n",
      "vida NOUN\n",
      "? PUNCT\n",
      ", PUNCT\n",
      "escribió VERB\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "Oración: el hijo de enrique peña nieto y la hija de angélica rivera, más que hermanos, se han convertido en grandes amigos y las fotos que comparten en sus respectivas cuentas en instagram muestran lo bien que se llevan.\n",
      "\n",
      "el DET\n",
      "hijo NOUN\n",
      "de ADP\n",
      "enrique PROPN\n",
      "peña PROPN\n",
      "nieto PROPN\n",
      "y CCONJ\n",
      "la DET\n",
      "hija NOUN\n",
      "de ADP\n",
      "angélica PROPN\n",
      "rivera PROPN\n",
      ", PUNCT\n",
      "más ADV\n",
      "que SCONJ\n",
      "hermanos NOUN\n",
      ", PUNCT\n",
      "se PRON\n",
      "han VERB\n",
      "convertido VERB\n",
      "en ADP\n",
      "grandes ADJ\n",
      "amigos NOUN\n",
      "y CCONJ\n",
      "las DET\n",
      "fotos NOUN\n",
      "que SCONJ\n",
      "comparten AUX\n",
      "en ADP\n",
      "sus DET\n",
      "respectivas ADJ\n",
      "cuentas NOUN\n",
      "en ADP\n",
      "instagram PROPN\n",
      "muestran AUX\n",
      "lo PRON\n",
      "bien NOUN\n",
      "que SCONJ\n",
      "se PRON\n",
      "llevan AUX\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "Oración: si bien la hija mayor de la primera dama se lleva de maravilla con los tres hijos del esposo de su mamá, la poca diferencia de edad con alejandro peña, con quien se lleva sólo un año, hace que los jóvenes se entiendan a la perfección.\n",
      "\n",
      "si SCONJ\n",
      "bien ADV\n",
      "la DET\n",
      "hija NOUN\n",
      "mayor ADJ\n",
      "de ADP\n",
      "la DET\n",
      "primera ADJ\n",
      "dama NOUN\n",
      "se PRON\n",
      "lleva VERB\n",
      "de ADP\n",
      "maravilla NOUN\n",
      "con ADP\n",
      "los DET\n",
      "tres NUM\n",
      "hijos NOUN\n",
      "del ADP\n",
      "esposo NOUN\n",
      "de ADP\n",
      "su DET\n",
      "mamá NOUN\n",
      ", PUNCT\n",
      "la DET\n",
      "poca DET\n",
      "diferencia NOUN\n",
      "de ADP\n",
      "edad NOUN\n",
      "con ADP\n",
      "alejandro PROPN\n",
      "peña PROPN\n",
      ", PUNCT\n",
      "con ADP\n",
      "quien PRON\n",
      "se PRON\n",
      "lleva VERB\n",
      "sólo ADV\n",
      "un DET\n",
      "año NOUN\n",
      ", PUNCT\n",
      "hace VERB\n",
      "que SCONJ\n",
      "los DET\n",
      "jóvenes NOUN\n",
      "se PRON\n",
      "entiendan VERB\n",
      "a ADP\n",
      "la DET\n",
      "perfección NOUN\n",
      ". PUNCT\n",
      "\n",
      " SPACE\n",
      "Oración: alejandro peña pretelini es el único hijo varón de enrique peña nieto y mónica pretelini, se ha destacado por ser un hermano protector y muy cariñoso, siempre cerca de sus hermanas paulina y nicole peña, tanto de sus hermanastras sofía, fernanda y regina castro.\n",
      "alejandro PROPN\n",
      "peña PROPN\n",
      "pretelini PROPN\n",
      "es AUX\n",
      "el DET\n",
      "único ADJ\n",
      "hijo NOUN\n",
      "varón ADJ\n",
      "de ADP\n",
      "enrique PROPN\n",
      "peña PROPN\n",
      "nieto PROPN\n",
      "y CCONJ\n",
      "mónica PROPN\n",
      "pretelini PROPN\n",
      ", PUNCT\n",
      "se PRON\n",
      "ha AUX\n",
      "destacado VERB\n",
      "por ADP\n",
      "ser VERB\n",
      "un DET\n",
      "hermano NOUN\n",
      "protector ADJ\n",
      "y CCONJ\n",
      "muy ADV\n",
      "cariñoso ADJ\n",
      ", PUNCT\n",
      "siempre ADV\n",
      "cerca ADV\n",
      "de ADP\n",
      "sus DET\n",
      "hermanas NOUN\n",
      "paulina ADJ\n",
      "y CCONJ\n",
      "nicole PROPN\n",
      "peña PROPN\n",
      ", PUNCT\n",
      "tanto ADV\n",
      "de ADP\n",
      "sus DET\n",
      "hermanastras NOUN\n",
      "sofía PROPN\n",
      ", PUNCT\n",
      "fernanda PROPN\n",
      "y CCONJ\n",
      "regina PROPN\n",
      "castro PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc.sents:\n",
    "    print(\"Oración: {}\".format(sentence))\n",
    "    for token in sentence:\n",
    "        print(token.text, token.pos_)\n",
    "        n_words_text = len(filtered_tokens_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252 8 31.5 4.190476190476191 34.92063492063492 50.0 58.60055865921788 15.079365079365079 15.079365079365079 13.88888888888889 11.507936507936508 9.523809523809524 5.555555555555555 6.349206349206349 3.1746031746031744\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords  \n",
    "from nltk import word_tokenize, sent_tokenize  \n",
    "from string import punctuation\n",
    "\n",
    "from lexical_diversity import lex_div as ld\n",
    "\n",
    "text = text.replace(r\"http\\S+\", \"\")\n",
    "text = text.replace(r\"http\", \"\")\n",
    "text = text.replace(r\"@\\S+\", \"\")\n",
    "text = text.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "text = text.lower()\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "list_tokens = []\n",
    "list_tags = []\n",
    "n_sents = 0\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    n_sents += 1\n",
    "    for token in sentence:\n",
    "        list_tokens.append(token.text)\n",
    "        list_tags.append(token.pos_)\n",
    "\n",
    "n_tags = nltk.Counter(list_tags)\n",
    "fdist = FreqDist(list_tokens)\n",
    "        \n",
    "# complexity features\n",
    "n_words = len(list_tokens)\n",
    "avg_word_sentences = (float(n_words) / n_sents)\n",
    "word_size = sum(len(word) for word in list_tokens) / n_words\n",
    "unique_words = (len(fdist.hapaxes()) / n_words) * 100\n",
    "ttr = ld.ttr(list_tokens) * 100\n",
    "mltd = ld.mtld(list_tokens)\n",
    "\n",
    "# lexical features\n",
    "propn_ratio = (n_tags['PROPN'] / n_words) * 100 \n",
    "noun_ratio = (n_tags['NOUN'] / n_words) * 100 \n",
    "adp_ratio = (n_tags['ADP'] / n_words) * 100\n",
    "det_ratio = (n_tags['DET'] / n_words) * 100\n",
    "punct_ratio = (n_tags['PUNCT'] / n_words) * 100 \n",
    "pron_ratio = (n_tags['PRON'] / n_words) * 100\n",
    "verb_ratio = (n_tags['VERB'] / n_words) * 100\n",
    "adv_ratio = (n_tags['ADV'] / n_words) * 100\n",
    "\n",
    "print(n_words, n_sents, avg_word_sentences, word_size, unique_words, ttr, mltd, propn_ratio, noun_ratio, adp_ratio, det_ratio, punct_ratio, \n",
    "      pron_ratio, verb_ratio, adv_ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply it to the full corpus with iterrows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57.5 s, sys: 1.45 s, total: 59 s\n",
      "Wall time: 59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from lexical_diversity import lex_div as ld\n",
    "nlp = spacy.load('es_core_news_lg')\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "df['Label'] = labelencoder.fit_transform(df['Category'])\n",
    "\n",
    "# empty lists and df\n",
    "df_features = pd.DataFrame()\n",
    "list_text = []\n",
    "list_nsentences = []\n",
    "list_nwords = []\n",
    "list_words_sent = []\n",
    "list_word_size = []\n",
    "list_unique_words = []\n",
    "list_ttr = []\n",
    "list_mltd = []\n",
    "list_propn_ratio = [] \n",
    "list_noun_ratio = []\n",
    "list_adp_ratio = []\n",
    "list_det_ratio = []\n",
    "list_punct_ratio = []\n",
    "list_pron_ratio = []\n",
    "list_verb_ratio = []\n",
    "list_adv_ratio = []\n",
    "\n",
    "# df iteration\n",
    "for n, row in df.iterrows():\n",
    "    text = df['Text'].iloc[n]\n",
    "    \n",
    "    text = text.replace(r\"http\\S+\", \"\")\n",
    "    text = text.replace(r\"http\", \"\")\n",
    "    text = text.replace(r\"@\\S+\", \"\")\n",
    "    text = text.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "    text = text.lower()\n",
    "\n",
    "    doc = nlp(text)\n",
    "\n",
    "    list_tokens = []\n",
    "    list_tags = []\n",
    "    n_sents = 0\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        n_sents += 1\n",
    "        for token in sentence:\n",
    "            list_tokens.append(token.text)\n",
    "            list_tags.append(token.pos_)\n",
    "\n",
    "    n_tags = nltk.Counter(list_tags)\n",
    "    fdist = FreqDist(list_tokens)\n",
    "\n",
    "    # complexity features\n",
    "    n_words = len(list_tokens)\n",
    "    avg_word_sentences = (float(n_words) / n_sents)\n",
    "    word_size = sum(len(word) for word in list_tokens) / n_words\n",
    "    unique_words = (len(fdist.hapaxes()) / n_words) * 100\n",
    "    ttr = ld.ttr(list_tokens) * 100\n",
    "    mltd = ld.mtld(list_tokens)\n",
    "\n",
    "    # lexical features\n",
    "    propn_ratio = (n_tags['PROPN'] / n_words) * 100 \n",
    "    noun_ratio = (n_tags['NOUN'] / n_words) * 100 \n",
    "    adp_ratio = (n_tags['ADP'] / n_words) * 100\n",
    "    det_ratio = (n_tags['DET'] / n_words) * 100\n",
    "    punct_ratio = (n_tags['PUNCT'] / n_words) * 100 \n",
    "    pron_ratio = (n_tags['PRON'] / n_words) * 100\n",
    "    verb_ratio = (n_tags['VERB'] / n_words) * 100\n",
    "    adv_ratio = (n_tags['ADV'] / n_words) * 100\n",
    "    \n",
    "    # appending on lists\n",
    "    list_text.append(text)\n",
    "    list_nsentences.append(n_sents)\n",
    "    list_nwords.append(n_words)\n",
    "    list_words_sent.append(avg_word_sentences)\n",
    "    list_word_size.append(word_size)\n",
    "    list_unique_words.append(unique_words)\n",
    "    list_ttr.append(ttr)\n",
    "    list_mltd.append(mltd)\n",
    "    list_propn_ratio.append(propn_ratio)\n",
    "    list_noun_ratio.append(noun_ratio)\n",
    "    list_adp_ratio.append(adp_ratio)\n",
    "    list_det_ratio.append(det_ratio)\n",
    "    list_punct_ratio.append(punct_ratio)\n",
    "    list_pron_ratio.append(pron_ratio)\n",
    "    list_verb_ratio.append(verb_ratio)\n",
    "    list_adv_ratio.append(adv_ratio)\n",
    "    \n",
    "# dataframe\n",
    "df_features['text'] = list_text\n",
    "df_features['n_sents'] = list_nsentences\n",
    "df_features['n_words'] = list_nwords\n",
    "df_features['avg_words_sents'] = list_words_sent\n",
    "df_features['word_size'] = list_word_size\n",
    "df_features['unique_words'] = list_unique_words\n",
    "df_features['ttr'] = list_ttr\n",
    "df_features['mltd'] = list_mltd\n",
    "df_features['propn_ratio'] = list_propn_ratio\n",
    "df_features['noun_ratio'] = list_noun_ratio\n",
    "df_features['adp_ratio'] = list_adp_ratio\n",
    "df_features['det_ratio'] = list_det_ratio\n",
    "df_features['punct_ratio'] = list_punct_ratio\n",
    "df_features['pron_ratio'] = list_pron_ratio\n",
    "df_features['verb_ratio'] = list_verb_ratio\n",
    "df_features['adv_ratio'] = list_adv_ratio\n",
    "df_features['label'] = df['Label']\n",
    "\n",
    "df_features.to_csv('../data/spanish_corpus_features_v3.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>n_sents</th>\n",
       "      <th>n_words</th>\n",
       "      <th>avg_words_sents</th>\n",
       "      <th>word_size</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>ttr</th>\n",
       "      <th>mltd</th>\n",
       "      <th>propn_ratio</th>\n",
       "      <th>noun_ratio</th>\n",
       "      <th>adp_ratio</th>\n",
       "      <th>det_ratio</th>\n",
       "      <th>punct_ratio</th>\n",
       "      <th>pron_ratio</th>\n",
       "      <th>verb_ratio</th>\n",
       "      <th>adv_ratio</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sofía castro y alejandro peña pretelini: una i...</td>\n",
       "      <td>8</td>\n",
       "      <td>252</td>\n",
       "      <td>31.500000</td>\n",
       "      <td>4.190476</td>\n",
       "      <td>34.920635</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>58.600559</td>\n",
       "      <td>15.079365</td>\n",
       "      <td>15.079365</td>\n",
       "      <td>13.888889</td>\n",
       "      <td>11.507937</td>\n",
       "      <td>9.523810</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>6.349206</td>\n",
       "      <td>3.174603</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>un paso más cerca de hacer los exámenes 'onlin...</td>\n",
       "      <td>9</td>\n",
       "      <td>486</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>4.255144</td>\n",
       "      <td>32.716049</td>\n",
       "      <td>44.238683</td>\n",
       "      <td>41.283136</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>15.226337</td>\n",
       "      <td>12.345679</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>18.930041</td>\n",
       "      <td>1.234568</td>\n",
       "      <td>3.292181</td>\n",
       "      <td>1.646091</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>esto es lo que los científicos realmente piens...</td>\n",
       "      <td>31</td>\n",
       "      <td>980</td>\n",
       "      <td>31.612903</td>\n",
       "      <td>4.815306</td>\n",
       "      <td>26.020408</td>\n",
       "      <td>38.571429</td>\n",
       "      <td>80.551467</td>\n",
       "      <td>4.795918</td>\n",
       "      <td>17.857143</td>\n",
       "      <td>13.979592</td>\n",
       "      <td>12.755102</td>\n",
       "      <td>11.836735</td>\n",
       "      <td>2.551020</td>\n",
       "      <td>10.306122</td>\n",
       "      <td>4.693878</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inicia impresión de boletas para elección pres...</td>\n",
       "      <td>11</td>\n",
       "      <td>369</td>\n",
       "      <td>33.545455</td>\n",
       "      <td>4.728997</td>\n",
       "      <td>22.764228</td>\n",
       "      <td>37.398374</td>\n",
       "      <td>50.995314</td>\n",
       "      <td>4.065041</td>\n",
       "      <td>22.493225</td>\n",
       "      <td>18.157182</td>\n",
       "      <td>15.176152</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>2.710027</td>\n",
       "      <td>7.317073</td>\n",
       "      <td>0.271003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a *number* día del mundial\\nfifa.com sigue la ...</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>4.461538</td>\n",
       "      <td>48.461538</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>47.081602</td>\n",
       "      <td>14.615385</td>\n",
       "      <td>14.615385</td>\n",
       "      <td>17.692308</td>\n",
       "      <td>13.846154</td>\n",
       "      <td>9.230769</td>\n",
       "      <td>3.076923</td>\n",
       "      <td>4.615385</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>interpol ordena detención inmediata de osorio ...</td>\n",
       "      <td>4</td>\n",
       "      <td>116</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>4.793103</td>\n",
       "      <td>48.275862</td>\n",
       "      <td>63.793103</td>\n",
       "      <td>63.025950</td>\n",
       "      <td>12.068966</td>\n",
       "      <td>16.379310</td>\n",
       "      <td>18.965517</td>\n",
       "      <td>12.931034</td>\n",
       "      <td>12.068966</td>\n",
       "      <td>2.586207</td>\n",
       "      <td>5.172414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\"los ninis\" más ricos y poderosos del país: hi...</td>\n",
       "      <td>5</td>\n",
       "      <td>211</td>\n",
       "      <td>42.200000</td>\n",
       "      <td>3.668246</td>\n",
       "      <td>35.071090</td>\n",
       "      <td>50.236967</td>\n",
       "      <td>50.913142</td>\n",
       "      <td>6.635071</td>\n",
       "      <td>16.113744</td>\n",
       "      <td>11.848341</td>\n",
       "      <td>11.374408</td>\n",
       "      <td>9.004739</td>\n",
       "      <td>2.369668</td>\n",
       "      <td>6.161137</td>\n",
       "      <td>5.687204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>para todo sacan lo del populismo, ni siquiera ...</td>\n",
       "      <td>12</td>\n",
       "      <td>416</td>\n",
       "      <td>34.666667</td>\n",
       "      <td>4.139423</td>\n",
       "      <td>32.932692</td>\n",
       "      <td>46.875000</td>\n",
       "      <td>66.856042</td>\n",
       "      <td>6.009615</td>\n",
       "      <td>17.067308</td>\n",
       "      <td>15.625000</td>\n",
       "      <td>9.855769</td>\n",
       "      <td>12.980769</td>\n",
       "      <td>4.807692</td>\n",
       "      <td>10.576923</td>\n",
       "      <td>2.403846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>conapred investiga acto de racismo en el pumas...</td>\n",
       "      <td>6</td>\n",
       "      <td>227</td>\n",
       "      <td>37.833333</td>\n",
       "      <td>4.101322</td>\n",
       "      <td>35.682819</td>\n",
       "      <td>51.541850</td>\n",
       "      <td>66.635851</td>\n",
       "      <td>10.572687</td>\n",
       "      <td>15.859031</td>\n",
       "      <td>13.656388</td>\n",
       "      <td>11.013216</td>\n",
       "      <td>13.215859</td>\n",
       "      <td>3.083700</td>\n",
       "      <td>9.251101</td>\n",
       "      <td>2.643172</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cristiano ronaldo acepta dos años de prisión\\n...</td>\n",
       "      <td>17</td>\n",
       "      <td>590</td>\n",
       "      <td>34.705882</td>\n",
       "      <td>4.276271</td>\n",
       "      <td>24.576271</td>\n",
       "      <td>35.932203</td>\n",
       "      <td>46.584855</td>\n",
       "      <td>5.084746</td>\n",
       "      <td>17.966102</td>\n",
       "      <td>14.237288</td>\n",
       "      <td>12.711864</td>\n",
       "      <td>10.677966</td>\n",
       "      <td>1.864407</td>\n",
       "      <td>8.474576</td>\n",
       "      <td>3.050847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  n_sents  n_words  \\\n",
       "0  sofía castro y alejandro peña pretelini: una i...        8      252   \n",
       "1  un paso más cerca de hacer los exámenes 'onlin...        9      486   \n",
       "2  esto es lo que los científicos realmente piens...       31      980   \n",
       "3  inicia impresión de boletas para elección pres...       11      369   \n",
       "4  a *number* día del mundial\\nfifa.com sigue la ...        5      130   \n",
       "5  interpol ordena detención inmediata de osorio ...        4      116   \n",
       "6  \"los ninis\" más ricos y poderosos del país: hi...        5      211   \n",
       "7  para todo sacan lo del populismo, ni siquiera ...       12      416   \n",
       "8  conapred investiga acto de racismo en el pumas...        6      227   \n",
       "9  cristiano ronaldo acepta dos años de prisión\\n...       17      590   \n",
       "\n",
       "   avg_words_sents  word_size  unique_words        ttr       mltd  \\\n",
       "0        31.500000   4.190476     34.920635  50.000000  58.600559   \n",
       "1        54.000000   4.255144     32.716049  44.238683  41.283136   \n",
       "2        31.612903   4.815306     26.020408  38.571429  80.551467   \n",
       "3        33.545455   4.728997     22.764228  37.398374  50.995314   \n",
       "4        26.000000   4.461538     48.461538  60.000000  47.081602   \n",
       "5        29.000000   4.793103     48.275862  63.793103  63.025950   \n",
       "6        42.200000   3.668246     35.071090  50.236967  50.913142   \n",
       "7        34.666667   4.139423     32.932692  46.875000  66.856042   \n",
       "8        37.833333   4.101322     35.682819  51.541850  66.635851   \n",
       "9        34.705882   4.276271     24.576271  35.932203  46.584855   \n",
       "\n",
       "   propn_ratio  noun_ratio  adp_ratio  det_ratio  punct_ratio  pron_ratio  \\\n",
       "0    15.079365   15.079365  13.888889  11.507937     9.523810    5.555556   \n",
       "1    16.666667   15.226337  12.345679  11.111111    18.930041    1.234568   \n",
       "2     4.795918   17.857143  13.979592  12.755102    11.836735    2.551020   \n",
       "3     4.065041   22.493225  18.157182  15.176152    11.111111    2.710027   \n",
       "4    14.615385   14.615385  17.692308  13.846154     9.230769    3.076923   \n",
       "5    12.068966   16.379310  18.965517  12.931034    12.068966    2.586207   \n",
       "6     6.635071   16.113744  11.848341  11.374408     9.004739    2.369668   \n",
       "7     6.009615   17.067308  15.625000   9.855769    12.980769    4.807692   \n",
       "8    10.572687   15.859031  13.656388  11.013216    13.215859    3.083700   \n",
       "9     5.084746   17.966102  14.237288  12.711864    10.677966    1.864407   \n",
       "\n",
       "   verb_ratio  adv_ratio  label  \n",
       "0    6.349206   3.174603      1  \n",
       "1    3.292181   1.646091      1  \n",
       "2   10.306122   4.693878      1  \n",
       "3    7.317073   0.271003      1  \n",
       "4    4.615385   1.538462      1  \n",
       "5    5.172414   0.000000      0  \n",
       "6    6.161137   5.687204      0  \n",
       "7   10.576923   2.403846      1  \n",
       "8    9.251101   2.643172      1  \n",
       "9    8.474576   3.050847      1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
