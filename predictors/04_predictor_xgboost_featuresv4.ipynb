{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor with complexity and stylometric/lexical features\n",
    "\n",
    "1. Load model\n",
    "2. Extract features\n",
    "3. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=1, nthread=1,\n",
       "              num_parallel_tree=1, random_state=43, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=0.9775967413441956, seed=43, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = pickle.load(open('../predictors/fake_news_predictorv2.pkl', 'rb'))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract features\n",
    "\n",
    "We are going tu use the last feature extractor located on /feature_extraction, in this case the version v4. This extractor does:\n",
    "\n",
    "- Clean the text from the headline and the news content\n",
    "- Extract complexity features from headline\n",
    "- Extract complexity features from news text content\n",
    "- Extract stylometrix features from news text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "from lexical_diversity import lex_div as ld\n",
    "\n",
    "def get_news_features(headline, text):\n",
    "    nlp = spacy.load('es_core_news_lg')\n",
    "    \n",
    "    ## headline ##\n",
    "    headline = headline.replace(r\"http\\S+\", \"\")\n",
    "    headline = headline.replace(r\"http\", \"\")\n",
    "    headline = headline.replace(r\"@\\S+\", \"\")\n",
    "    headline = headline.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "    headline = headline.lower()\n",
    "    doc_h = nlp(headline)\n",
    "\n",
    "    list_tokens_h = []\n",
    "    list_tags_h = []\n",
    "    n_sents_h = 0\n",
    "\n",
    "    for sentence_h in doc_h.sents:\n",
    "        n_sents_h += 1\n",
    "        for token in sentence_h:\n",
    "            list_tokens_h.append(token.text)\n",
    "\n",
    "    fdist_h = FreqDist(list_tokens_h)\n",
    "\n",
    "    # headline complexity features\n",
    "    n_words_h = len(list_tokens_h)\n",
    "    word_size_h = sum(len(word) for word in list_tokens_h) / n_words_h\n",
    "    unique_words_h = (len(fdist_h.hapaxes()) / n_words_h) * 100\n",
    "    ttr_h = ld.ttr(list_tokens_h) * 100\n",
    "    mltd_h = ld.mtld(list_tokens_h)\n",
    "\n",
    "\n",
    "\n",
    "    ## text content ##   \n",
    "    text = text.replace(r\"http\\S+\", \"\")\n",
    "    text = text.replace(r\"http\", \"\")\n",
    "    text = text.replace(r\"@\\S+\", \"\")\n",
    "    text = text.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "\n",
    "    list_tokens = []\n",
    "    list_pos = []\n",
    "    list_tag = []\n",
    "    n_sents = 0\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        n_sents += 1\n",
    "        for token in sentence:\n",
    "            list_tokens.append(token.text)\n",
    "            list_pos.append(token.pos_)\n",
    "            list_tag.append(token.tag_)\n",
    "\n",
    "    n_pos = nltk.Counter(list_pos)\n",
    "    n_tag = nltk.Counter(list_tag)\n",
    "    fdist = FreqDist(list_tokens)\n",
    "\n",
    "    # complexity features\n",
    "    n_words = len(list_tokens)\n",
    "    avg_word_sentences = (float(n_words) / n_sents)\n",
    "    word_size = sum(len(word) for word in list_tokens) / n_words\n",
    "    unique_words = (len(fdist.hapaxes()) / n_words) * 100\n",
    "    ttr = ld.ttr(list_tokens) * 100\n",
    "    mltd = ld.mtld(list_tokens)\n",
    "\n",
    "    # lexical features\n",
    "    n_quotes = n_tag['PUNCT__PunctType=Quot']\n",
    "    quotes_ratio = (n_quotes / n_words) * 100\n",
    "    propn_ratio = (n_pos['PROPN'] / n_words) * 100 \n",
    "    noun_ratio = (n_pos['NOUN'] / n_words) * 100 \n",
    "    adp_ratio = (n_pos['ADP'] / n_words) * 100\n",
    "    det_ratio = (n_pos['DET'] / n_words) * 100\n",
    "    punct_ratio = (n_pos['PUNCT'] / n_words) * 100 \n",
    "    pron_ratio = (n_pos['PRON'] / n_words) * 100\n",
    "    verb_ratio = (n_pos['VERB'] / n_words) * 100\n",
    "    adv_ratio = (n_pos['ADV'] / n_words) * 100\n",
    "    sym_ratio = (n_tag['SYM'] / n_words) * 100\n",
    "\n",
    "    # create df\n",
    "\n",
    "    df_features = pd.DataFrame({'n_sents': [n_sents], 'n_words': [n_words], 'avg_words_sents': [avg_word_sentences], \n",
    "                'word_size': [word_size], 'unique_words': [unique_words], 'ttr': [ttr], 'mltd': [mltd], 'n_words_h': [n_words_h],\n",
    "                'word_size_h': [word_size_h], 'unique_words_h': [unique_words_h], 'mltd_h': [mltd_h], 'n_quotes': [n_quotes],\n",
    "                'quotes_ratio': [quotes_ratio], 'propn_ratio': [propn_ratio], 'noun_ratio': [noun_ratio], 'adp_ratio': [adp_ratio],\n",
    "                'det_ratio': [det_ratio], 'punct_ratio': [punct_ratio], 'pron_ratio': [pron_ratio], 'verb_ratio': [verb_ratio],\n",
    "                'adv_ratio': [adv_ratio], 'sym_ratio': [sym_ratio]})\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3c79dfe73079>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'This is a fake new \\nWith a probability: %.0f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_predict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_features' is not defined"
     ]
    }
   ],
   "source": [
    "X_predict = df_features\n",
    "\n",
    "if (model.predict(X_predict)[0]) == 0:\n",
    "    print('This is a fake new \\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][0])*100), '%')\n",
    "else:\n",
    "    print('This is a legitimate new\\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][1])*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('../predictors/fake_news_predictorv2.pkl', 'rb'))\n",
    "nlp = spacy.load('es_core_news_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert headline: La Fundación CEPS convirtió a Pablo Iglesias en “beneficiario” del dinero recibido de narcodictaduras\n",
      "Insert text: La Fundación CEPS, principal impulsora de Podemos, se convirtió en un mecanismo transmisor de dinero que cobraba de dictaduras y convertía en “beneficiarios” de esos fondos a quienes intervenían en los supuestos trabajos de investigación y asesoría a regímenes políticos populistas. Pablo Iglesias era en los años 2008 y 2009 miembro destacado del Consejo Ejecutivo de la Fundación. Era nada menos que el responsable del área de Investigación. Y eso hizo que se convirtiera en “beneficiario” del dinero recibido de narcodictaduras.  Pablo Iglesias, de hecho, figura como uno de los nueve responsables de la captación de fondos y beneficiario, por lo tanto, de 1,36 millones pagados por el Gobierno bolivariano de Venezuela. Así figura en los archivos de CEPS a los que ha tenido acceso OKDIARIO. Una documentación que confirma en un largo listado de contratos y convenios firmados con narcodictaduras todas las informaciones expuestas hasta el momento sobre la llegada de dinero del régimen chavista y que desvela, además, que el dinero tenía como beneficiarios a los que “se encuentren en condiciones de tomar parte, de uno o de otro modo, en las actividades que organiza la Fundación”, como destacan los propios documentos de CEPS. E Iglesias era una de las personas más destacadas en ese aspecto.  La Fundación CEPS convirtió a Pablo Iglesias en “beneficiario” del dinero recibido de narcodictaduras  La lista de contratos es incalculable a lo largo de los años 2004 a 2013. Todos esos convenios se cerraban bajo impulso directo de la narcodictadura chavista con el propósito de apadrinar a los futuros impulsores de Podemos. Y entre los años 2008 y 2009 figuraba en la cúspide de la Fundación CEPS, tal y como recoge su propia documentación, Pablo Iglesias Turrión. Lo hacía, además, con un cargo que le convertía en figura imprescindible en la inmensa mayoría de los trabajos: responsable de Investigación. Y la mayoría de los convenios incluían una parte de supuesta investigación.  Importancia en la estructura  Un punto destacado en la documentación de CEPS demuestra la importancia de este tipo de cargos de primera fila en la Fundación. Y es que esos puestos se convertían directamente en “beneficiarios” de los fondos: “Son beneficiarios de la Fundación CEPS todas aquellas personas que se encuentren en condiciones de tomar parte, de uno o de otro modo, en las actividades que organiza la Fundación”, señala el propio documento de la entidad. Y Pablo Iglesias no sólo formaba parte de la cúpula ejecutiva del organismo, sino que, además, se encargaba directamente de la investigación en cada campo.  En total, el Consejo Ejecutivo estaba compuesto por nueve personas en la etapa de máximo protagonismo de Iglesias. Sus compañeros eran Rubén Martínez Dalmau -vicepresidente segundo del Gobierno de la Comunidad Valenciana en estos momentos-; Alberto Montero Soler -hasta hace cuatro años diputado nacional de Podemos y el profesor de la Universidad de Málaga que contrató a Errejón para estudiar la vivienda en Andalucía sin moverse de Madrid-; Adoración Guamán Hernández -recién aupada a directora general de Coordinación Institucional por Martínez Dalmau-; Fabiola Meco Tébar -diputada autonómica de Podemos-; Antonio de Cabo de la Vega -profesor de la Complutense ligado a la corriente de Carolina Bescansa y muy cercano a Gerardo Pisarello-; Roberto Viciano Pastor -impulsor de CEPS y de todo lo que ha rodeado a Podemos-; José Manuel de Pablos e Isabel Luján Gimeno, igualmente del entorno de Podemos. Todos ellos podían acogerse al punto que determinaba que aquello que intervenían en las labores eran “beneficiarios” de la Fundación.  Hay que recordar que Podemos se enfrenta ya a una imputación por la creación de una caja B y el uso irregular del dinero que llegaba al partido. Y que esta documentación a la que ha tenido acceso OKDIARIO aporta innumerable información sobre el inicio de esta historia: sobre la llegada de dinero desde dictaduras populistas a los líderes de la formación morada.  Los documentos que publica este diario reflejan el estado de cuentas de la Fundación CEPS a los largo de los años 2004 a 2013, es decir, los ejercicios previos a la creación oficial de Podemos. Los años en los que varias narcodictaduras financiaban a los impulsores del partido populista para que llegase a eclosionar y contagiase el sistema democrático español. Y en esos documentos figura ya de forma muy destacada el nombre del actual vicepresidente del Gobierno de Pedro Sánchez. Pablo Iglesias aparece como responsable de la captación de 1,361 millones de euros del Gobierno de Venezuela entre los años 2008 y 2009, cuando él ocupaba un puesto clave en el Consejo Ejecutivo de la Fundación CEPS.  Hay que destacar igualmente que el fiscal general de EEUU, William P. Barr, ha presentado ya cargos criminales por narcotráfico y terrorismo contra el actual dictador venezolano, Nicolás Maduro. Tanto él como su predecesor Hugo Chávez han sido los grandes financiadores de los cabecillas de la formación morada. En concreto, la Fundación CEPS, de la que eran dirigentes Pablo Iglesias y Juan Carlos Monedero, recibió 7,1 millones de euros del régimen chavista. La documentación que ahora desvela OKDIARIO aporta una nueva prueba de la veracidad de estas informaciones y detalla el contenido de toda la lluvia de trabajos encargados a los supuestos expertos de CEPS para cerrar los muy lucrativos convenios.\n",
      "This is a legitimate! new\n",
      "With a probability: 86 %\n",
      "CPU times: user 3.56 s, sys: 2.28 s, total: 5.84 s\n",
      "Wall time: 30.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "from lexical_diversity import lex_div as ld\n",
    "import pickle\n",
    "\n",
    "from newspaper import Article\n",
    "\n",
    "from newspaper import Article\n",
    "\n",
    "headline = input('Insert headline: ')\n",
    "text= input('Insert text: ')\n",
    "\n",
    "df_features = get_news_features(headline, text)\n",
    "\n",
    "########## PREDICTIONS ##########\n",
    "X_predict = df_features\n",
    "\n",
    "if (model.predict(X_predict)[0]) == 0:\n",
    "    print('This is a fake new! \\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][0])*100), '%')\n",
    "else:\n",
    "    print('This is a legitimate! new\\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][1])*100), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_sents</th>\n",
       "      <th>n_words</th>\n",
       "      <th>avg_words_sents</th>\n",
       "      <th>word_size</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>ttr</th>\n",
       "      <th>mltd</th>\n",
       "      <th>n_words_h</th>\n",
       "      <th>word_size_h</th>\n",
       "      <th>unique_words_h</th>\n",
       "      <th>...</th>\n",
       "      <th>quotes_ratio</th>\n",
       "      <th>propn_ratio</th>\n",
       "      <th>noun_ratio</th>\n",
       "      <th>adp_ratio</th>\n",
       "      <th>det_ratio</th>\n",
       "      <th>punct_ratio</th>\n",
       "      <th>pron_ratio</th>\n",
       "      <th>verb_ratio</th>\n",
       "      <th>adv_ratio</th>\n",
       "      <th>sym_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>26</td>\n",
       "      <td>994</td>\n",
       "      <td>38.230769</td>\n",
       "      <td>4.77666</td>\n",
       "      <td>35.311871</td>\n",
       "      <td>44.969819</td>\n",
       "      <td>86.942711</td>\n",
       "      <td>19</td>\n",
       "      <td>5.526316</td>\n",
       "      <td>78.947368</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201207</td>\n",
       "      <td>8.450704</td>\n",
       "      <td>19.71831</td>\n",
       "      <td>17.002012</td>\n",
       "      <td>12.877264</td>\n",
       "      <td>8.249497</td>\n",
       "      <td>1.710262</td>\n",
       "      <td>8.04829</td>\n",
       "      <td>2.313883</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_sents  n_words  avg_words_sents  word_size  unique_words        ttr  \\\n",
       "0       26      994        38.230769    4.77666     35.311871  44.969819   \n",
       "\n",
       "        mltd  n_words_h  word_size_h  unique_words_h  ...  quotes_ratio  \\\n",
       "0  86.942711         19     5.526316       78.947368  ...      0.201207   \n",
       "\n",
       "   propn_ratio  noun_ratio  adp_ratio  det_ratio  punct_ratio  pron_ratio  \\\n",
       "0     8.450704    19.71831  17.002012  12.877264     8.249497    1.710262   \n",
       "\n",
       "   verb_ratio  adv_ratio  sym_ratio  \n",
       "0     8.04829   2.313883        0.0  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
