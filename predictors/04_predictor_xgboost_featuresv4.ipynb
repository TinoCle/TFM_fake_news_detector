{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor with complexity and stylometric/lexical features\n",
    "\n",
    "1. Load model\n",
    "2. Extract features\n",
    "3. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=1, nthread=1,\n",
       "              num_parallel_tree=1, random_state=43, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=0.9775967413441956, seed=43, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = pickle.load(open('../predictors/fake_news_predictorv2.pkl', 'rb'))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract features\n",
    "\n",
    "We are going tu use the last feature extractor located on /feature_extraction, in this case the version v4. This extractor does:\n",
    "\n",
    "- Clean the text from the headline and the news content\n",
    "- Extract complexity features from headline\n",
    "- Extract complexity features from news text content\n",
    "- Extract stylometrix features from news text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "from lexical_diversity import lex_div as ld\n",
    "\n",
    "def get_news_features(headline, text):\n",
    "    nlp = spacy.load('es_core_news_lg')\n",
    "    \n",
    "    ## headline ##\n",
    "    headline = headline.replace(r\"http\\S+\", \"\")\n",
    "    headline = headline.replace(r\"http\", \"\")\n",
    "    headline = headline.replace(r\"@\\S+\", \"\")\n",
    "    headline = headline.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "    headline = headline.lower()\n",
    "    doc_h = nlp(headline)\n",
    "\n",
    "    list_tokens_h = []\n",
    "    list_tags_h = []\n",
    "    n_sents_h = 0\n",
    "\n",
    "    for sentence_h in doc_h.sents:\n",
    "        n_sents_h += 1\n",
    "        for token in sentence_h:\n",
    "            list_tokens_h.append(token.text)\n",
    "\n",
    "    fdist_h = FreqDist(list_tokens_h)\n",
    "\n",
    "    # headline complexity features\n",
    "    n_words_h = len(list_tokens_h)\n",
    "    word_size_h = sum(len(word) for word in list_tokens_h) / n_words_h\n",
    "    unique_words_h = (len(fdist_h.hapaxes()) / n_words_h) * 100\n",
    "    ttr_h = ld.ttr(list_tokens_h) * 100\n",
    "    mltd_h = ld.mtld(list_tokens_h)\n",
    "\n",
    "\n",
    "\n",
    "    ## text content ##   \n",
    "    text = text.replace(r\"http\\S+\", \"\")\n",
    "    text = text.replace(r\"http\", \"\")\n",
    "    text = text.replace(r\"@\\S+\", \"\")\n",
    "    text = text.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "    text = text.lower()\n",
    "    doc = nlp(text)\n",
    "\n",
    "    list_tokens = []\n",
    "    list_pos = []\n",
    "    list_tag = []\n",
    "    n_sents = 0\n",
    "\n",
    "    for sentence in doc.sents:\n",
    "        n_sents += 1\n",
    "        for token in sentence:\n",
    "            list_tokens.append(token.text)\n",
    "            list_pos.append(token.pos_)\n",
    "            list_tag.append(token.tag_)\n",
    "\n",
    "    n_pos = nltk.Counter(list_pos)\n",
    "    n_tag = nltk.Counter(list_tag)\n",
    "    fdist = FreqDist(list_tokens)\n",
    "\n",
    "    # complexity features\n",
    "    n_words = len(list_tokens)\n",
    "    avg_word_sentences = (float(n_words) / n_sents)\n",
    "    word_size = sum(len(word) for word in list_tokens) / n_words\n",
    "    unique_words = (len(fdist.hapaxes()) / n_words) * 100\n",
    "    ttr = ld.ttr(list_tokens) * 100\n",
    "    mltd = ld.mtld(list_tokens)\n",
    "\n",
    "    # lexical features\n",
    "    n_quotes = n_tag['PUNCT__PunctType=Quot']\n",
    "    quotes_ratio = (n_quotes / n_words) * 100\n",
    "    propn_ratio = (n_pos['PROPN'] / n_words) * 100 \n",
    "    noun_ratio = (n_pos['NOUN'] / n_words) * 100 \n",
    "    adp_ratio = (n_pos['ADP'] / n_words) * 100\n",
    "    det_ratio = (n_pos['DET'] / n_words) * 100\n",
    "    punct_ratio = (n_pos['PUNCT'] / n_words) * 100 \n",
    "    pron_ratio = (n_pos['PRON'] / n_words) * 100\n",
    "    verb_ratio = (n_pos['VERB'] / n_words) * 100\n",
    "    adv_ratio = (n_pos['ADV'] / n_words) * 100\n",
    "    sym_ratio = (n_tag['SYM'] / n_words) * 100\n",
    "\n",
    "    # create df\n",
    "\n",
    "    df_features = pd.DataFrame({'n_sents': [n_sents], 'n_words': [n_words], 'avg_words_sents': [avg_word_sentences], \n",
    "                'word_size': [word_size], 'unique_words': [unique_words], 'ttr': [ttr], 'mltd': [mltd], 'n_words_h': [n_words_h],\n",
    "                'word_size_h': [word_size_h], 'unique_words_h': [unique_words_h], 'mltd_h': [mltd_h], 'n_quotes': [n_quotes],\n",
    "                'quotes_ratio': [quotes_ratio], 'propn_ratio': [propn_ratio], 'noun_ratio': [noun_ratio], 'adp_ratio': [adp_ratio],\n",
    "                'det_ratio': [det_ratio], 'punct_ratio': [punct_ratio], 'pron_ratio': [pron_ratio], 'verb_ratio': [verb_ratio],\n",
    "                'adv_ratio': [adv_ratio], 'sym_ratio': [sym_ratio]})\n",
    "    \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a legitimate new\n",
      "With a probability: 98 %\n"
     ]
    }
   ],
   "source": [
    "X_predict = df_features\n",
    "\n",
    "if (model.predict(X_predict)[0]) == 0:\n",
    "    print('This is a fake new \\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][0])*100), '%')\n",
    "else:\n",
    "    print('This is a legitimate new\\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][1])*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New's headline text: Los estudiantes convocan huelga contra Isabel Celaá e instan a los ministros de Podemos a apoyar el paro \"por coherencia\"\n",
      "New's content text: En este otoño caliente para la escuela por rebrotes de coronavirus habrá padres que no lleven a sus hijos a clase porque tienen miedo, profesores que se ausentarán de sus tareas para protestar contra las medidas de autonomías como Madrid, Andalucía o Murcia y estudiantes que se plantan para denunciar \"la inacción\" y \"la desidia\" de la ministra Isabel Celaá. La comunidad educativa considera que las medidas que este jueves cerrarán el Gobierno y las CCAA \"llegan tarde\".  El Sindicato de Estudiantes ha convocado este miércoles cuatro días de huelga en toda España en las etapas de ESO, Bachillerato y FP. A diferencia de los sindicatos de docentes, apuntan directamente al Gobierno central porque \"ha echado balones fuera y ha descargado toda la tarea sobre las consejerías\": \"La última responsabilidad la tiene el Ministerio\", dicen.  Izquierda Unida también está presionando, por su parte, para que Celaá y las CCAA acuerden una reducción de las ratios, entre otras medidas. Pide que el número máximo de alumnos por aula sea 20 en Primaria (frente a los 25 actuales), 20 en la ESO (ahora son 25) y 25 en el Bachillerato (ante los 30 previstos).   Celaá cree que hay un \"exceso de alarma\" con la vuelta al cole \"El Ministerio de Educación en todo este tiempo no ha promovido una vuelta efectiva a las aulas, no ha movido un dedo en cinco meses. No garantiza ni la calidad ni la educación presencial, pone en riesgo la salud de los profesores, de los alumnos y de las familias\", expresa Ana García, portavoz de este colectivo cercano a Unidas Podemos.  García hace un llamamiento expreso a los ministros de Podemos a que \"no toleren esta situación\" y respalden expresamente la convocatoria de huelga: \"Han salido criticando a Celaá, pero la crítica no es suficiente si no va acompañada de medidas. No pueden permitir esta situación desde el Gobierno del que forman parte y tienen que apoyar públicamente la huelga y posicionarse a favor de nosotros. Hacemos un llamamiento a Pablo Iglesias específicamente. Si es coherente con su defensa de una política de izquierdas y los intereses de la gente no hay otra salida que apoyar la huelga\".  La huelga estudiantil se celebrará el 16, el 17 y el 18 de septiembre en toda España, coincidiendo con la primera semana en están ya funcionando las clases en todo el Estado. Además, habrá paros en Madrid el 9 (cuando protestan los docentes de Secundaria) y el 10 (cuando se celebran las movilizaciones de CCOO, UGT y STES).  Los motivos que esgrimen son que la ministra no ha promovido ni acordado una bajada de ratios (piden grupos de un máximo de 15 estudiantes por profesor y ahora son entre 25 y 30), ni se han contratado suficientes profesores (CCOO estima que harían falta 165.000 y el incremento será como mucho de 30.000 según las cifras dadas por Pedro Sánchez).  También reclaman habilitar realizar contrataciones adicionales de personal de limpieza para que desinfecten de forma continua las aulas y que haya un enfermero en cada centro educativo, una posibilidad que las consejerías han descartado. Los estudiantes agrupados en este colectivo denuncian \"la constante política de bandazos\" de Celaá y también advierten que \"la situación es dramática en las universidades\": \"En las universidades se plantean clases digitales. Mucha gente no ha podido seguir el curso y, como consecuencia de haber levantado la mano durante el Bachillerato, las notas de corte han subido de forma espectacular y muchos alumnos se han quedado fuera\".\n",
      "This is a legitimate! new\n",
      "With a probability: 96 %\n",
      "CPU times: user 6.8 s, sys: 2.94 s, total: 9.73 s\n",
      "Wall time: 26.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "from lexical_diversity import lex_div as ld\n",
    "import pickle\n",
    "\n",
    "model = pickle.load(open('../predictors/fake_news_predictorv2.pkl', 'rb'))\n",
    "nlp = spacy.load('es_core_news_lg')\n",
    "\n",
    "headline = input(\"New's headline text: \")\n",
    "text = input(\"New's content text: \")\n",
    "\n",
    "df_features = get_news_features(headline, text)\n",
    "\n",
    "########## PREDICTIONS ##########\n",
    "X_predict = df_features\n",
    "\n",
    "if (model.predict(X_predict)[0]) == 0:\n",
    "    print('This is a fake new! \\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][0])*100), '%')\n",
    "else:\n",
    "    print('This is a legitimate! new\\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][1])*100), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
