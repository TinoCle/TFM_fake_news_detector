{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictor with complexity and stylometric/lexical features\n",
    "\n",
    "1. Load model\n",
    "2. Extract features\n",
    "3. Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, eval_metric='auc',\n",
       "              gamma=0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=1, nthread=1,\n",
       "              num_parallel_tree=1, random_state=43, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=0.9775967413441956, seed=43, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "model = pickle.load(open('../predictors/fake_news_predictorv2.pkl', 'rb'))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extract features\n",
    "\n",
    "We are going tu use the last feature extractor located on /feature_extraction, in this case the version v4. This extractor does:\n",
    "\n",
    "- Clean the text from the headline and the news content\n",
    "- Extract complexity features from headline\n",
    "- Extract complexity features from news text content\n",
    "- Extract stylometrix features from news text content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New's headline text: Madrid pide revocar el auto que anula prohibir fumar en la calle y reprocha al juez que se \"extralimite\"\n",
      "New's content text: La Comunidad de Madrid ha reclamado la revocación del auto del Juzgado de lo Contencioso-Administrativo número 2 de Madrid que anula elcierre del ocio nocturno y la prohibición de fumar en vía pública sin distancia de seguridad, al apreciar que el magistrado se \"extralimita\" en su resolución.  Así lo establece la Abogacía de la Comunidad en Madrid en el recurso ya interpuesto contra el rechazo a la ratificación de estas medidas para alegar que el magistrado \"desborda\" en su resolución el mero acto de ratificar o no las nuevas medidas con un pronunciamiento \"contradictorio\".  En este recurso la Comunidad de Madrid recrimina que el juzgado parece aludir a que la orden no afecta ni limita derechos fundamentales y debería haber dictado un auto \"sin más consideraciones\".  \"No hay duda que la labor del órgano judicial se circunscribe a ratificar únicamente las medidas que puedan restringir la libertad u otro derecho fundamental\", detallan los servicios jurídicos de la Comunidad de Madrid.  Por tanto, aprecian esa \"contradicción\" al pronunciarse que estas limitaciones preventivas ante el Covid-19 no se ciñen al aspecto de los derechos o libertades fundamentales pero luego realiza una serie de consideraciones, como formular como vía adecuada dentro del marco normativo actual la declaración de un estado de alarma individualizado.  Además, afea al juez Alfonso Villagómez Cebrián que no haya atendido su petición de aclaración porque existe \"una sustancial diferencia\" entre no ratificar la Orden 1008/2020 por considerar que se basa en una disposición ineficaz y \"entender que solo puede dictarse en el marco de un estado de alarma; a entender que la no ratificación obedece a que no hay una afectación de los derechos fundamentales\".  \"Desde luego, ante tan contradictorios fundamentos, desde una perspectiva de seguridad jurídica, teniendo en cuenta que muchas de las medidas adoptadas resultan especialmente controvertidas, y siendo conscientes del eco mediático de la decisión, era especialmente deseable la aclaración\", afea la Abogacía de la Comunidad de Madrid.  El juez declinó esa solicitud de aclaraciones al alcance de su auto al defender que su auto desprende una \"claridad expositiva y resolutoria fuera de toda duda\". Además, deslizó reproches a la Comunidad de Madrid recalcando que el \"no cogobierna\" el Consejo de Gobierno.  En contraposición, el recurso del Gobierno regional recrimina al juez que en su auto, en lugar de estudiar la afectación de los concretos derechos fundamentales que pudieran tener las medidas adoptadas, como así exponían en su consulta jurídica sobre las nuevas medidas para la nueva normalidad, realiza \"una valoración genérica de la limitación de derechos fundamentales, considerando que el instrumento que permite una suspensión generalizada es la declaración del estado de alarma\".  \"De ahí que las consideraciones del auto, refiriendo la necesidad de un estado de alarma para la suspensión de derechos fundamentales, no guarden relación ni las medidas adoptadas en la Orden 1008/2020, ni con el planteamiento efectuado por esta Administración en la solicitud cursada\", ahonda la Comunidad.  De hecho, Madrid defiende la \"prudencia\" de la orden anulada, pues introduce una \"recomendación\" de reducir encuentros sociales fuera del grupo de convivencia estable, donde no habría \"limitación del derecho fundamental\".  También entiende que el registro de clientes de ocio nocturno desprende una afección \"muy moderada\" y que la limitación de salidas en residencias se justifica al ser los mayores un colectivo de riesgo ante la pandemia.  LA ANULACIÓN DE LA ORDEN Pero además, el Ejecutivo autonómico replica que el rechazar la ratificación bajo la circunstancias de no haberse publicado en el Boletín Oficial del Estado (BOE) la instrucción genérica del Ministerio de Sanidad sobre estas medidas \"no es acertada\", pues es un dictamen cuyos efectos radican en las administración y no en los ciudadanos.  Y es que esa declaración actuaciones coordinadas fue aprobada por unanimidad en el Pleno del Consejo Interterritorial del Sistema Nacional de Salud, que es el órgano encargado de velar por la cohesión de las actuaciones de los servicios de salud en los diferentes territorios.  En este sentido, la orden del Ministerio acorde con esa disposición aprobada en el seno del Consejo Interterritorial \"obliga\" a las autonomías pero no a los ciudadanos, no siendo necesario su publicación en el BOE.  \"La declaración de actuaciones coordinadas (del Ministerio) no tiene un efecto directo sobre la población sino sobre las restantes administraciones, actuando como marco general a fin de obtener una forma de proceder unívoca ante la situación sanitaria\".  Y \"mucho menos\", tal y como argumenta el Ejecutivo autonómico, puede \"afirmarse que la publicación de esta orden es requisito para su validez\".\n",
      "CPU times: user 3.16 s, sys: 1.36 s, total: 4.52 s\n",
      "Wall time: 26.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_sents</th>\n",
       "      <th>n_words</th>\n",
       "      <th>avg_words_sents</th>\n",
       "      <th>word_size</th>\n",
       "      <th>unique_words</th>\n",
       "      <th>ttr</th>\n",
       "      <th>mltd</th>\n",
       "      <th>n_words_h</th>\n",
       "      <th>word_size_h</th>\n",
       "      <th>unique_words_h</th>\n",
       "      <th>mltd_h</th>\n",
       "      <th>n_quotes</th>\n",
       "      <th>quotes_ratio</th>\n",
       "      <th>propn_ratio</th>\n",
       "      <th>noun_ratio</th>\n",
       "      <th>adp_ratio</th>\n",
       "      <th>det_ratio</th>\n",
       "      <th>punct_ratio</th>\n",
       "      <th>pron_ratio</th>\n",
       "      <th>verb_ratio</th>\n",
       "      <th>adv_ratio</th>\n",
       "      <th>sym_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>864</td>\n",
       "      <td>48.0</td>\n",
       "      <td>4.748843</td>\n",
       "      <td>24.884259</td>\n",
       "      <td>59.931507</td>\n",
       "      <td>69.69613</td>\n",
       "      <td>21</td>\n",
       "      <td>4.095238</td>\n",
       "      <td>80.952381</td>\n",
       "      <td>61.74</td>\n",
       "      <td>44</td>\n",
       "      <td>5.092593</td>\n",
       "      <td>2.546296</td>\n",
       "      <td>20.37037</td>\n",
       "      <td>16.550926</td>\n",
       "      <td>14.699074</td>\n",
       "      <td>11.458333</td>\n",
       "      <td>1.157407</td>\n",
       "      <td>7.75463</td>\n",
       "      <td>4.513889</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_sents  n_words  avg_words_sents  word_size  unique_words        ttr  \\\n",
       "0       18      864             48.0   4.748843     24.884259  59.931507   \n",
       "\n",
       "       mltd  n_words_h  word_size_h  unique_words_h  mltd_h  n_quotes  \\\n",
       "0  69.69613         21     4.095238       80.952381   61.74        44   \n",
       "\n",
       "   quotes_ratio  propn_ratio  noun_ratio  adp_ratio  det_ratio  punct_ratio  \\\n",
       "0      5.092593     2.546296    20.37037  16.550926  14.699074    11.458333   \n",
       "\n",
       "   pron_ratio  verb_ratio  adv_ratio  sym_ratio  \n",
       "0    1.157407     7.75463   4.513889        0.0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "from lexical_diversity import lex_div as ld\n",
    "nlp = spacy.load('es_core_news_lg')\n",
    "\n",
    "headline = input(\"New's headline text: \")\n",
    "text = input(\"New's content text: \")\n",
    " \n",
    "    \n",
    "## headline ##\n",
    "headline = headline.replace(r\"http\\S+\", \"\")\n",
    "headline = headline.replace(r\"http\", \"\")\n",
    "headline = headline.replace(r\"@\\S+\", \"\")\n",
    "headline = headline.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "headline = headline.lower()\n",
    "doc_h = nlp(headline)\n",
    "\n",
    "list_tokens_h = []\n",
    "list_tags_h = []\n",
    "n_sents_h = 0\n",
    "\n",
    "for sentence_h in doc_h.sents:\n",
    "    n_sents_h += 1\n",
    "    for token in sentence_h:\n",
    "        list_tokens_h.append(token.text)\n",
    "\n",
    "fdist_h = FreqDist(list_tokens_h)\n",
    "    \n",
    "# headline complexity features\n",
    "n_words_h = len(list_tokens_h)\n",
    "word_size_h = sum(len(word) for word in list_tokens_h) / n_words_h\n",
    "unique_words_h = (len(fdist_h.hapaxes()) / n_words_h) * 100\n",
    "ttr_h = ld.ttr(list_tokens_h) * 100\n",
    "mltd_h = ld.mtld(list_tokens_h)\n",
    "\n",
    "\n",
    "\n",
    "## text content ##   \n",
    "text = text.replace(r\"http\\S+\", \"\")\n",
    "text = text.replace(r\"http\", \"\")\n",
    "text = text.replace(r\"@\\S+\", \"\")\n",
    "text = text.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "text = text.lower()\n",
    "doc = nlp(text)\n",
    "\n",
    "list_tokens = []\n",
    "list_pos = []\n",
    "list_tag = []\n",
    "n_sents = 0\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    n_sents += 1\n",
    "    for token in sentence:\n",
    "        list_tokens.append(token.text)\n",
    "        list_pos.append(token.pos_)\n",
    "        list_tag.append(token.tag_)\n",
    "\n",
    "n_pos = nltk.Counter(list_pos)\n",
    "n_tag = nltk.Counter(list_tag)\n",
    "fdist = FreqDist(list_tokens)\n",
    "\n",
    "# complexity features\n",
    "n_words = len(list_tokens)\n",
    "avg_word_sentences = (float(n_words) / n_sents)\n",
    "word_size = sum(len(word) for word in list_tokens) / n_words\n",
    "unique_words = (len(fdist.hapaxes()) / n_words) * 100\n",
    "# ttr = ld.ttr(list_tokens) * 100\n",
    "mltd = ld.mtld(list_tokens)\n",
    "\n",
    "# lexical features\n",
    "n_quotes = n_tag['PUNCT__PunctType=Quot']\n",
    "quotes_ratio = (n_quotes / n_words) * 100\n",
    "propn_ratio = (n_pos['PROPN'] / n_words) * 100 \n",
    "noun_ratio = (n_pos['NOUN'] / n_words) * 100 \n",
    "adp_ratio = (n_pos['ADP'] / n_words) * 100\n",
    "det_ratio = (n_pos['DET'] / n_words) * 100\n",
    "punct_ratio = (n_pos['PUNCT'] / n_words) * 100 \n",
    "pron_ratio = (n_pos['PRON'] / n_words) * 100\n",
    "verb_ratio = (n_pos['VERB'] / n_words) * 100\n",
    "adv_ratio = (n_pos['ADV'] / n_words) * 100\n",
    "sym_ratio = (n_tag['SYM'] / n_words) * 100\n",
    "\n",
    "# create \n",
    "\n",
    "df_features = pd.DataFrame({'n_sents': [n_sents], 'n_words': [n_words], 'avg_words_sents': [avg_word_sentences], \n",
    "            'word_size': [word_size], 'unique_words': [unique_words], 'ttr': [ttr], 'mltd': [mltd], 'n_words_h': [n_words_h],\n",
    "            'word_size_h': [word_size_h], 'unique_words_h': [unique_words_h], 'mltd_h': [mltd_h], 'n_quotes': [n_quotes],\n",
    "            'quotes_ratio': [quotes_ratio], 'propn_ratio': [propn_ratio], 'noun_ratio': [noun_ratio], 'adp_ratio': [adp_ratio],\n",
    "            'det_ratio': [det_ratio], 'punct_ratio': [punct_ratio], 'pron_ratio': [pron_ratio], 'verb_ratio': [verb_ratio],\n",
    "            'adv_ratio': [adv_ratio], 'sym_ratio': [sym_ratio]})\n",
    "            \n",
    "pd.options.display.max_columns = None\n",
    "df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a legitimate new\n",
      "With a probability: 98 %\n"
     ]
    }
   ],
   "source": [
    "X_predict = df_features\n",
    "\n",
    "if (model.predict(X_predict)[0]) == 0:\n",
    "    print('This is a fake new \\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][0])*100), '%')\n",
    "else:\n",
    "    print('This is a legitimate new\\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][1])*100), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New's headline text: Sánchez ‘premia’ la labor del Ejército rebajando la inversión en Defensa un 27% en 2020\n",
      "New's content text: Malos tiempos para el Ejército. El incremento de los gastos que ha tenido que afrontar el Gobierno de Pedro Sánchez y Pablo Iglesias por las nuevas prestaciones y aplazamientos de impuestos a los más afectados por la crisis del coronavirus ha castigado a Defensa. Según los datos de ejecución presupuestaria de junio, último mes publicado por Hacienda, Sánchez ha reducido en un 27% las inversiones en Defensa respecto al primer semestre de 2017.  Mientras el Ejército se sumaba a las tareas de ayuda para paliar los efectos del coronavirus en lo peor de la pandemia, levantando hospitales de campaña y desinfectando residencias de ancianos y otros lugares a través de la UME, el Gobierno reducía sus inversiones en el sector hasta los 547 millones de euros. En 2019, las inversiones a cierre de junio fueron de 749 millones. La caída es del citado 27%.  En cambio, el Gobierno ha mejorado en el semestre las inversiones en el sector civil un 15%, hasta casi 1.000 millones de euros, principalmente por el Ministerio de Fomento, que incrementa su gasto en el periodo en un 17,8% -hasta los 662 millones-.  Por lo tanto, en un periodo de incremento de las necesidades de gasto por la pandemia, el Gobierno de Sánchez ha decidido reducir el gasto e intentar ahorrar en los costes militares. En el apartado de ‘Pagos no financieros’ de la ejecución del Presupuesto hasta junio, las inversiones en Defensa son prácticamente la única partida que desciende, junto a las transferencias a la CNMC y otras entidades públicas.  Crecen en cambio los gastos de personal, por el incremento de los salarios de los funcionarios, a lo que hay que sumar el aumento de los altos cargos y personal de confianza del Ejecutivo formado en enero por PSOE y Podemos.  Con la reducción del gasto en Defensa el Gobierno compensa en parte los mayores fondos utilizados para gastos sanitarios. En concreto, según el informe de Hacienda, se han destinado 993 millones de euros a gastos sanitarios y de farmacia en el primer semestre, partida que existió en 2019. A cambio, este año no ha habido que afrontar 319 millones de costes electorales que sí hubo el año pasado.  Nuevo plan de inversiones  Tras la reducción de inversiones en Defensa de 2020, Sánchez ha aprovechado el pacto alcanzado en Bruselas para poner en marcha un Fondo de Reconstrucción europeo que dará a España 140.000 millones de euros para reunirse inmediatamente con los dirigentes de Airbus y anunciar un ambicioso plan de inversiones.  El pasado 31 de julio, unos días después de la reunión en Bruselas, Sánchez anunció inversiones de 185 millones de euros en la transformación de tres aviones A330 y a la adquisición de cuatro aviones C295 para Salvamento Marítimo, así como a otra serie de proyectos ligados a Defensa. Este plan se financiará con los fondos europeos. A cambio, Airbus se comprometió al mantenimiento de la plantilla en España, amenazada por más despidos ante la falta de negocio por la pandemia.  Se da la circunstancia de que el ahora presidente del Gobierno señaló en una entrevista en 2014 que el Ministerio de Defensa sobraba. Sánchez señaló cuando era líder de la oposición que era necesario destinar más dinero a la erradicación de la pobreza que a Defensa. Son de sobra conocidas también las ideas sobre el Ejército de los socios de Gobierno de Sánchez, Podemos.\n",
      "This is a legitimate! new\n",
      "With a probability: 94 %\n",
      "CPU times: user 3.11 s, sys: 1.8 s, total: 4.91 s\n",
      "Wall time: 13.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import FreqDist\n",
    "from lexical_diversity import lex_div as ld\n",
    "import pickle\n",
    "\n",
    "model = pickle.load(open('../predictors/fake_news_predictorv2.pkl', 'rb'))\n",
    "nlp = spacy.load('es_core_news_lg')\n",
    "\n",
    "headline = input(\"New's headline text: \")\n",
    "text = input(\"New's content text: \")\n",
    " \n",
    "    \n",
    "## headline ##\n",
    "headline = headline.replace(r\"http\\S+\", \"\")\n",
    "headline = headline.replace(r\"http\", \"\")\n",
    "headline = headline.replace(r\"@\\S+\", \"\")\n",
    "headline = headline.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "headline = headline.lower()\n",
    "doc_h = nlp(headline)\n",
    "\n",
    "list_tokens_h = []\n",
    "list_tags_h = []\n",
    "n_sents_h = 0\n",
    "\n",
    "for sentence_h in doc_h.sents:\n",
    "    n_sents_h += 1\n",
    "    for token in sentence_h:\n",
    "        list_tokens_h.append(token.text)\n",
    "\n",
    "fdist_h = FreqDist(list_tokens_h)\n",
    "    \n",
    "# headline complexity features\n",
    "n_words_h = len(list_tokens_h)\n",
    "word_size_h = sum(len(word) for word in list_tokens_h) / n_words_h\n",
    "unique_words_h = (len(fdist_h.hapaxes()) / n_words_h) * 100\n",
    "# ttr_h = ld.ttr(list_tokens_h) * 100\n",
    "mltd_h = ld.mtld(list_tokens_h)\n",
    "\n",
    "\n",
    "\n",
    "## text content ##   \n",
    "text = text.replace(r\"http\\S+\", \"\")\n",
    "text = text.replace(r\"http\", \"\")\n",
    "text = text.replace(r\"@\\S+\", \"\")\n",
    "text = text.replace(r\"(?<!\\n)\\n(?!\\n)\", \" \")\n",
    "text = text.lower()\n",
    "doc = nlp(text)\n",
    "\n",
    "list_tokens = []\n",
    "list_pos = []\n",
    "list_tag = []\n",
    "n_sents = 0\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    n_sents += 1\n",
    "    for token in sentence:\n",
    "        list_tokens.append(token.text)\n",
    "        list_pos.append(token.pos_)\n",
    "        list_tag.append(token.tag_)\n",
    "\n",
    "n_pos = nltk.Counter(list_pos)\n",
    "n_tag = nltk.Counter(list_tag)\n",
    "fdist = FreqDist(list_tokens)\n",
    "\n",
    "# complexity features\n",
    "n_words = len(list_tokens)\n",
    "avg_word_sentences = (float(n_words) / n_sents)\n",
    "word_size = sum(len(word) for word in list_tokens) / n_words\n",
    "unique_words = (len(fdist.hapaxes()) / n_words) * 100\n",
    "ttr = ld.ttr(list_tokens) * 100\n",
    "mltd = ld.mtld(list_tokens)\n",
    "\n",
    "# lexical features\n",
    "n_quotes = n_tag['PUNCT__PunctType=Quot']\n",
    "quotes_ratio = (n_quotes / n_words) * 100\n",
    "propn_ratio = (n_pos['PROPN'] / n_words) * 100 \n",
    "noun_ratio = (n_pos['NOUN'] / n_words) * 100 \n",
    "adp_ratio = (n_pos['ADP'] / n_words) * 100\n",
    "det_ratio = (n_pos['DET'] / n_words) * 100\n",
    "punct_ratio = (n_pos['PUNCT'] / n_words) * 100 \n",
    "pron_ratio = (n_pos['PRON'] / n_words) * 100\n",
    "verb_ratio = (n_pos['VERB'] / n_words) * 100\n",
    "adv_ratio = (n_pos['ADV'] / n_words) * 100\n",
    "sym_ratio = (n_tag['SYM'] / n_words) * 100\n",
    "\n",
    "# create dataframe with features\n",
    "\n",
    "df_features = pd.DataFrame({'n_sents': [n_sents], 'n_words': [n_words], 'avg_words_sents': [avg_word_sentences], \n",
    "            'word_size': [word_size], 'unique_words': [unique_words], 'ttr': [ttr], 'mltd': [mltd], 'n_words_h': [n_words_h],\n",
    "            'word_size_h': [word_size_h], 'unique_words_h': [unique_words_h], 'mltd_h': [mltd_h], 'n_quotes': [n_quotes],\n",
    "            'quotes_ratio': [quotes_ratio], 'propn_ratio': [propn_ratio], 'noun_ratio': [noun_ratio], 'adp_ratio': [adp_ratio],\n",
    "            'det_ratio': [det_ratio], 'punct_ratio': [punct_ratio], 'pron_ratio': [pron_ratio], 'verb_ratio': [verb_ratio],\n",
    "            'adv_ratio': [adv_ratio], 'sym_ratio': [sym_ratio]})\n",
    "\n",
    "\n",
    "########## PREDICTIONS ##########\n",
    "X_predict = df_features\n",
    "\n",
    "if (model.predict(X_predict)[0]) == 0:\n",
    "    print('This is a fake new! \\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][0])*100), '%')\n",
    "else:\n",
    "    print('This is a legitimate! new\\nWith a probability: %.0f' % ((model.predict_proba(X_predict)[0][1])*100), '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
